{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIErXPbqIRbE"
   },
   "source": [
    "# Multi-Query Retrieval in RAG: A Step-by-Step Guide\n",
    "\n",
    "In this guide, we will implement Multi-Query retrieval using LangChain and OpenAI. This approach will help improve the retrieval of relevant documents from a knowledge base by generating multiple queries to retrieve more diverse results. Afterward, we will compare the baseline RAG approach (using a single query) with the enhanced multi-query approach.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "058GoFXwJWnk"
   },
   "source": [
    "## Step 1: Set Up the Environment\n",
    "\n",
    "To get started, we need to install the necessary libraries and configure our environment. This includes installing packages like langchain, openai, chromadb, and wikipedia that will help with document loading, vector storage, and response generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oATnT5bQfVpD"
   },
   "source": [
    "### Install Required Libraries\n",
    "\n",
    "First, run the following command to install the essential libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fpfnQa9h54ti",
    "outputId": "5f357157-65ee-43cb-b160-d828c1f357ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.8)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
      "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.2.10)\n",
      "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.5.20)\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.9)\n",
      "Requirement already satisfied: wikipedia in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.21)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.143)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.6.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.54.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.54.4)\n",
      "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.9.2)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.115.5)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.32.1)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.7.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.20.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.49b2)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.28.2)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.20.3)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.6)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.5)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.68.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.2.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.13.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (31.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (5.0.1)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.11)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.27.2)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.17.2)\n",
      "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.41.3)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
      "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_community) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (0.7.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.28.2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-proto==1.28.2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.23.4)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2.0.36,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.26.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.6)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain_community tiktoken langchain-openai chromadb langchain wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPLTXdg3f8NT"
   },
   "source": [
    "### Set Up API Key\n",
    "Next, set up your OpenAI API key to interact with large language models. You can set them like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2IcWwF1b6RZj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"YOUR_OPENAI_API_KEY\"\n",
    "os.environ['USER_AGENT'] = 'myagent'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LEuI59n9KaWP"
   },
   "source": [
    "## **Step 2:** Set Up the Vector Store\n",
    "\n",
    "Now, we need to ingest some documents into a vector store. This will allow us to retrieve relevant documents based on the user's queries. For this example, we will use Wikipedia as our document source and Chroma as the vector store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucid_enSgmP8"
   },
   "source": [
    "### Load Documents from Wikipedia\n",
    "\n",
    "We'll use LangChain's WikipediaLoader to load articles on large language models (LLMs). After that, we'll split the text into manageable chunks to prepare them for embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ifPqd5gB9YOE"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "loader = WikipediaLoader(query=\"large language models\")\n",
    "documents = loader.load()\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "splits = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pyjm8SCTmPbu",
    "outputId": "a8ddd16a-2f79-4d8a-91cf-ef970607f9c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'Large language model', 'summary': 'A large language model (LLM) is a type of computational model designed for natural language processing tasks such as language generation. As language models, LLMs acquire these abilities by learning statistical relationships from vast amounts of text during a self-supervised and semi-supervised training process.\\nThe largest and most capable LLMs are artificial neural networks built with a decoder-only transformer-based architecture, enabling efficient processing and generation of large-scale text data. Modern models can be fine-tuned for specific tasks, or be guided by prompt engineering. These models acquire predictive power regarding syntax, semantics, and ontologies inherent in human language corpora, but they also inherit inaccuracies and biases present in the data on which they are trained.', 'source': 'https://en.wikipedia.org/wiki/Large_language_model'}, page_content='A large language model (LLM) is a type of computational model designed for natural language processing tasks such as language generation. As language models, LLMs acquire these abilities by learning statistical relationships from vast amounts of text during a self-supervised and semi-supervised training process.\\nThe largest and most capable LLMs are artificial neural networks built with a decoder-only transformer-based architecture, enabling efficient processing and generation of large-scale text data. Modern models can be fine-tuned for specific tasks, or be guided by prompt engineering. These models acquire predictive power regarding syntax, semantics, and ontologies inherent in human language corpora, but they also inherit inaccuracies and biases present in the data on which they are trained.\\n\\n\\n== History ==\\n\\nBefore 2017, there were a few language models that were large as compared to capacities then available. In the 1990s, the IBM alignment models pioneered statistical language modelling. A smoothed n-gram model in 2001 trained on 0.3 billion words achieved state-of-the-art perplexity at the time. In the 2000s, as Internet use became prevalent, some researchers constructed Internet-scale language datasets (\"web as corpus\"), upon which they trained statistical language models. In 2009, in most language processing tasks, statistical language models dominated over symbolic language models, as they can usefully ingest large datasets.'),\n",
       " Document(metadata={'title': 'Large language model', 'summary': 'A large language model (LLM) is a type of computational model designed for natural language processing tasks such as language generation. As language models, LLMs acquire these abilities by learning statistical relationships from vast amounts of text during a self-supervised and semi-supervised training process.\\nThe largest and most capable LLMs are artificial neural networks built with a decoder-only transformer-based architecture, enabling efficient processing and generation of large-scale text data. Modern models can be fine-tuned for specific tasks, or be guided by prompt engineering. These models acquire predictive power regarding syntax, semantics, and ontologies inherent in human language corpora, but they also inherit inaccuracies and biases present in the data on which they are trained.', 'source': 'https://en.wikipedia.org/wiki/Large_language_model'}, page_content='After neural networks became dominant in image processing around 2012, they were applied to language modelling as well. Google converted its translation service to Neural Machine Translation in 2016. As it was before transformers, it was done by seq2seq deep LSTM networks.\\nAt the 2017 NeurIPS conference, Google researchers introduced the transformer architecture in their landmark paper \"Attention Is All You Need\". This paper\\'s goal was to improve upon 2014 seq2seq technology, and was based mainly on the attention mechanism developed by Bahdanau et al. in 2014. The following year in 2018, BERT was introduced and quickly became \"ubiquitous\". Though the original transformer has both encoder and decoder blocks, BERT is an encoder-only model.'),\n",
       " Document(metadata={'title': 'Large language model', 'summary': 'A large language model (LLM) is a type of computational model designed for natural language processing tasks such as language generation. As language models, LLMs acquire these abilities by learning statistical relationships from vast amounts of text during a self-supervised and semi-supervised training process.\\nThe largest and most capable LLMs are artificial neural networks built with a decoder-only transformer-based architecture, enabling efficient processing and generation of large-scale text data. Modern models can be fine-tuned for specific tasks, or be guided by prompt engineering. These models acquire predictive power regarding syntax, semantics, and ontologies inherent in human language corpora, but they also inherit inaccuracies and biases present in the data on which they are trained.', 'source': 'https://en.wikipedia.org/wiki/Large_language_model'}, page_content='Although decoder-only GPT-1 was introduced in 2018, it was GPT-2 in 2019 that caught widespread attention because OpenAI at first deemed it too powerful to release publicly, out of fear of malicious use. GPT-3 in 2020 went a step further and as of 2024 is available only via API with no offering of downloading the model to execute locally. But it was the 2022 consumer-facing browser-based ChatGPT that captured the imaginations of the general population and caused some media hype and online buzz. The 2023 GPT-4 was praised for its increased accuracy and as a \"holy grail\" for its multimodal capabilities. OpenAI did not reveal the high-level architecture and the number of parameters of GPT-4.\\nCompeting language models have for the most part been attempting to equal the GPT series, at least in terms of number of parameters.'),\n",
       " Document(metadata={'title': 'Large language model', 'summary': 'A large language model (LLM) is a type of computational model designed for natural language processing tasks such as language generation. As language models, LLMs acquire these abilities by learning statistical relationships from vast amounts of text during a self-supervised and semi-supervised training process.\\nThe largest and most capable LLMs are artificial neural networks built with a decoder-only transformer-based architecture, enabling efficient processing and generation of large-scale text data. Modern models can be fine-tuned for specific tasks, or be guided by prompt engineering. These models acquire predictive power regarding syntax, semantics, and ontologies inherent in human language corpora, but they also inherit inaccuracies and biases present in the data on which they are trained.', 'source': 'https://en.wikipedia.org/wiki/Large_language_model'}, page_content=\"Competing language models have for the most part been attempting to equal the GPT series, at least in terms of number of parameters.\\nSince 2022, source-available models have been gaining popularity, especially at first with BLOOM and LLaMA, though both have restrictions on the field of use. Mistral AI's models Mistral 7B and Mixtral 8x7b have the more permissive Apache License. As of June 2024, The Instruction fine tuned variant of the Llama 3 70 billion parameter model is the most powerful open LLM according to the LMSYS Chatbot Arena Leaderboard, being more powerful than GPT-3.5 but not as powerful as GPT-4.\\nAs of 2024, the largest and most capable models are all based on the Transformer architecture. Some recent implementations are based on other architectures, such as recurrent neural network variants and Mamba (a state space model).\"),\n",
       " Document(metadata={'title': 'Large language model', 'summary': 'A large language model (LLM) is a type of computational model designed for natural language processing tasks such as language generation. As language models, LLMs acquire these abilities by learning statistical relationships from vast amounts of text during a self-supervised and semi-supervised training process.\\nThe largest and most capable LLMs are artificial neural networks built with a decoder-only transformer-based architecture, enabling efficient processing and generation of large-scale text data. Modern models can be fine-tuned for specific tasks, or be guided by prompt engineering. These models acquire predictive power regarding syntax, semantics, and ontologies inherent in human language corpora, but they also inherit inaccuracies and biases present in the data on which they are trained.', 'source': 'https://en.wikipedia.org/wiki/Large_language_model'}, page_content='== Dataset preprocessing ==\\n\\n\\n=== Tokenization ===\\n\\nBecause machine learning algorithms process numbers rather than text, the text must be converted to numbers. In the first step, a vocabulary is decided upon, then integer indices are arbitra'),\n",
       " Document(metadata={'title': 'Language model', 'summary': 'A language model is a probabilistic model of a natural language. In 1980, the first significant statistical language model was proposed, and during the decade IBM performed ‘Shannon-style’ experiments, in which potential sources for language modeling improvement were identified by observing and analyzing the performance of human subjects in predicting or correcting text.\\nLanguage models are useful for a variety of tasks, including speech recognition (helping prevent predictions of low-probability (e.g. nonsense) sequences), machine translation, natural language generation (generating more human-like text), optical character recognition, route optimization, handwriting recognition, grammar induction, and information retrieval.\\nLarge language models, currently their most advanced form, are a combination of larger datasets (frequently using words scraped from the public internet), feedforward neural networks, and transformers. They have superseded recurrent neural network-based models, which had previously superseded the pure statistical models, such as word n-gram language model.', 'source': 'https://en.wikipedia.org/wiki/Language_model'}, page_content='A language model is a probabilistic model of a natural language. In 1980, the first significant statistical language model was proposed, and during the decade IBM performed ‘Shannon-style’ experiments, in which potential sources for language modeling improvement were identified by observing and analyzing the performance of human subjects in predicting or correcting text.\\nLanguage models are useful for a variety of tasks, including speech recognition (helping prevent predictions of low-probability (e.g. nonsense) sequences), machine translation, natural language generation (generating more human-like text), optical character recognition, route optimization, handwriting recognition, grammar induction, and information retrieval.\\nLarge language models, currently their most advanced form, are a combination of larger datasets (frequently using words scraped from the public internet), feedforward neural networks, and transformers. They have superseded recurrent neural network-based models, which had previously superseded the pure statistical models, such as word n-gram language model.\\n\\n\\n== Pure statistical models ==\\n\\n\\n=== Models based on word n-grams ===\\n\\n\\n=== Exponential ===\\nMaximum entropy language models encode the relationship between a word and the n-gram history using feature functions. The equation is'),\n",
       " Document(metadata={'title': 'Language model', 'summary': 'A language model is a probabilistic model of a natural language. In 1980, the first significant statistical language model was proposed, and during the decade IBM performed ‘Shannon-style’ experiments, in which potential sources for language modeling improvement were identified by observing and analyzing the performance of human subjects in predicting or correcting text.\\nLanguage models are useful for a variety of tasks, including speech recognition (helping prevent predictions of low-probability (e.g. nonsense) sequences), machine translation, natural language generation (generating more human-like text), optical character recognition, route optimization, handwriting recognition, grammar induction, and information retrieval.\\nLarge language models, currently their most advanced form, are a combination of larger datasets (frequently using words scraped from the public internet), feedforward neural networks, and transformers. They have superseded recurrent neural network-based models, which had previously superseded the pure statistical models, such as word n-gram language model.', 'source': 'https://en.wikipedia.org/wiki/Language_model'}, page_content='P\\n        (\\n        \\n          w\\n          \\n            m\\n          \\n        \\n        ∣\\n        \\n          w\\n          \\n            1\\n          \\n        \\n        ,\\n        …\\n        ,\\n        \\n          w\\n          \\n            m\\n            −\\n            1\\n          \\n        \\n        )'),\n",
       " Document(metadata={'title': 'Language model', 'summary': 'A language model is a probabilistic model of a natural language. In 1980, the first significant statistical language model was proposed, and during the decade IBM performed ‘Shannon-style’ experiments, in which potential sources for language modeling improvement were identified by observing and analyzing the performance of human subjects in predicting or correcting text.\\nLanguage models are useful for a variety of tasks, including speech recognition (helping prevent predictions of low-probability (e.g. nonsense) sequences), machine translation, natural language generation (generating more human-like text), optical character recognition, route optimization, handwriting recognition, grammar induction, and information retrieval.\\nLarge language models, currently their most advanced form, are a combination of larger datasets (frequently using words scraped from the public internet), feedforward neural networks, and transformers. They have superseded recurrent neural network-based models, which had previously superseded the pure statistical models, such as word n-gram language model.', 'source': 'https://en.wikipedia.org/wiki/Language_model'}, page_content='1\\n          \\n        \\n        )\\n        =\\n        \\n          \\n            1\\n            \\n              Z\\n              (\\n              \\n                w\\n                \\n                  1\\n                \\n              \\n              ,\\n              …\\n              ,'),\n",
       " Document(metadata={'title': 'Language model', 'summary': 'A language model is a probabilistic model of a natural language. In 1980, the first significant statistical language model was proposed, and during the decade IBM performed ‘Shannon-style’ experiments, in which potential sources for language modeling improvement were identified by observing and analyzing the performance of human subjects in predicting or correcting text.\\nLanguage models are useful for a variety of tasks, including speech recognition (helping prevent predictions of low-probability (e.g. nonsense) sequences), machine translation, natural language generation (generating more human-like text), optical character recognition, route optimization, handwriting recognition, grammar induction, and information retrieval.\\nLarge language models, currently their most advanced form, are a combination of larger datasets (frequently using words scraped from the public internet), feedforward neural networks, and transformers. They have superseded recurrent neural network-based models, which had previously superseded the pure statistical models, such as word n-gram language model.', 'source': 'https://en.wikipedia.org/wiki/Language_model'}, page_content='…\\n              ,\\n              \\n                w\\n                \\n                  m\\n                  −\\n                  1\\n                \\n              \\n              )\\n            \\n          \\n        \\n        exp\\n        \\u2061\\n        (\\n        \\n          a\\n          \\n            T'),\n",
       " Document(metadata={'title': 'Language model', 'summary': 'A language model is a probabilistic model of a natural language. In 1980, the first significant statistical language model was proposed, and during the decade IBM performed ‘Shannon-style’ experiments, in which potential sources for language modeling improvement were identified by observing and analyzing the performance of human subjects in predicting or correcting text.\\nLanguage models are useful for a variety of tasks, including speech recognition (helping prevent predictions of low-probability (e.g. nonsense) sequences), machine translation, natural language generation (generating more human-like text), optical character recognition, route optimization, handwriting recognition, grammar induction, and information retrieval.\\nLarge language models, currently their most advanced form, are a combination of larger datasets (frequently using words scraped from the public internet), feedforward neural networks, and transformers. They have superseded recurrent neural network-based models, which had previously superseded the pure statistical models, such as word n-gram language model.', 'source': 'https://en.wikipedia.org/wiki/Language_model'}, page_content='a\\n          \\n            T\\n          \\n        \\n        f\\n        (\\n        \\n          w\\n          \\n            1\\n          \\n        \\n        ,\\n        …\\n        ,\\n        \\n          w\\n          \\n            m\\n          \\n        \\n        )\\n        )'),\n",
       " Document(metadata={'title': 'Language model', 'summary': 'A language model is a probabilistic model of a natural language. In 1980, the first significant statistical language model was proposed, and during the decade IBM performed ‘Shannon-style’ experiments, in which potential sources for language modeling improvement were identified by observing and analyzing the performance of human subjects in predicting or correcting text.\\nLanguage models are useful for a variety of tasks, including speech recognition (helping prevent predictions of low-probability (e.g. nonsense) sequences), machine translation, natural language generation (generating more human-like text), optical character recognition, route optimization, handwriting recognition, grammar induction, and information retrieval.\\nLarge language models, currently their most advanced form, are a combination of larger datasets (frequently using words scraped from the public internet), feedforward neural networks, and transformers. They have superseded recurrent neural network-based models, which had previously superseded the pure statistical models, such as word n-gram language model.', 'source': 'https://en.wikipedia.org/wiki/Language_model'}, page_content=')\\n        )\\n      \\n    \\n    {\\\\displaystyle P(w_{m}\\\\mid w_{1},\\\\ldots ,w_{m-1})={\\\\frac {1}{Z(w_{1},\\\\ldots ,w_{m-1})}}\\\\exp(a^{T}f(w_{1},\\\\ldots ,w_{m}))}'),\n",
       " Document(metadata={'title': 'Language model', 'summary': 'A language model is a probabilistic model of a natural language. In 1980, the first significant statistical language model was proposed, and during the decade IBM performed ‘Shannon-style’ experiments, in which potential sources for language modeling improvement were identified by observing and analyzing the performance of human subjects in predicting or correcting text.\\nLanguage models are useful for a variety of tasks, including speech recognition (helping prevent predictions of low-probability (e.g. nonsense) sequences), machine translation, natural language generation (generating more human-like text), optical character recognition, route optimization, handwriting recognition, grammar induction, and information retrieval.\\nLarge language models, currently their most advanced form, are a combination of larger datasets (frequently using words scraped from the public internet), feedforward neural networks, and transformers. They have superseded recurrent neural network-based models, which had previously superseded the pure statistical models, such as word n-gram language model.', 'source': 'https://en.wikipedia.org/wiki/Language_model'}, page_content='where \\n  \\n    \\n      \\n        Z\\n        (\\n        \\n          w\\n          \\n            1\\n          \\n        \\n        ,\\n        …\\n        ,\\n        \\n          w\\n          \\n            m\\n            −\\n            1\\n          \\n        \\n        )\\n      \\n    \\n    {\\\\displaystyle Z(w_{1},\\\\ldots ,w_{m-1})}\\n  \\n is the partition function, \\n  \\n    \\n      \\n        a'),\n",
       " Document(metadata={'title': 'Language model', 'summary': 'A language model is a probabilistic model of a natural language. In 1980, the first significant statistical language model was proposed, and during the decade IBM performed ‘Shannon-style’ experiments, in which potential sources for language modeling improvement were identified by observing and analyzing the performance of human subjects in predicting or correcting text.\\nLanguage models are useful for a variety of tasks, including speech recognition (helping prevent predictions of low-probability (e.g. nonsense) sequences), machine translation, natural language generation (generating more human-like text), optical character recognition, route optimization, handwriting recognition, grammar induction, and information retrieval.\\nLarge language models, currently their most advanced form, are a combination of larger datasets (frequently using words scraped from the public internet), feedforward neural networks, and transformers. They have superseded recurrent neural network-based models, which had previously superseded the pure statistical models, such as word n-gram language model.', 'source': 'https://en.wikipedia.org/wiki/Language_model'}, page_content='is the partition function, \\n  \\n    \\n      \\n        a\\n      \\n    \\n    {\\\\displaystyle a}\\n  \\n is the parameter vector, and \\n  \\n    \\n      \\n        f\\n        (\\n        \\n          w\\n          \\n            1\\n          \\n        \\n        ,\\n        …\\n        ,\\n        \\n          w\\n          \\n            m\\n          \\n        \\n        )\\n      \\n    \\n    {\\\\displaystyle f(w_{1},\\\\ldots ,w_{m})}'),\n",
       " Document(metadata={'title': 'Language model', 'summary': 'A language model is a probabilistic model of a natural language. In 1980, the first significant statistical language model was proposed, and during the decade IBM performed ‘Shannon-style’ experiments, in which potential sources for language modeling improvement were identified by observing and analyzing the performance of human subjects in predicting or correcting text.\\nLanguage models are useful for a variety of tasks, including speech recognition (helping prevent predictions of low-probability (e.g. nonsense) sequences), machine translation, natural language generation (generating more human-like text), optical character recognition, route optimization, handwriting recognition, grammar induction, and information retrieval.\\nLarge language models, currently their most advanced form, are a combination of larger datasets (frequently using words scraped from the public internet), feedforward neural networks, and transformers. They have superseded recurrent neural network-based models, which had previously superseded the pure statistical models, such as word n-gram language model.', 'source': 'https://en.wikipedia.org/wiki/Language_model'}, page_content=')\\n      \\n    \\n    {\\\\displaystyle f(w_{1},\\\\ldots ,w_{m})}\\n  \\n is the feature function. In the simplest case, the feature function is just an indicator of the presence of a certain n-gram. It is helpful to use a prior on \\n  \\n    \\n      \\n        a\\n      \\n    \\n    {\\\\displaystyle a}\\n  \\n or some form of regularization.\\nThe log-bilinear model is another example of an exponential language model.'),\n",
       " Document(metadata={'title': 'Language model', 'summary': 'A language model is a probabilistic model of a natural language. In 1980, the first significant statistical language model was proposed, and during the decade IBM performed ‘Shannon-style’ experiments, in which potential sources for language modeling improvement were identified by observing and analyzing the performance of human subjects in predicting or correcting text.\\nLanguage models are useful for a variety of tasks, including speech recognition (helping prevent predictions of low-probability (e.g. nonsense) sequences), machine translation, natural language generation (generating more human-like text), optical character recognition, route optimization, handwriting recognition, grammar induction, and information retrieval.\\nLarge language models, currently their most advanced form, are a combination of larger datasets (frequently using words scraped from the public internet), feedforward neural networks, and transformers. They have superseded recurrent neural network-based models, which had previously superseded the pure statistical models, such as word n-gram language model.', 'source': 'https://en.wikipedia.org/wiki/Language_model'}, page_content='=== Skip-gram model ===\\n\\n\\n== Neural models ==\\n\\n\\n=== Recurrent neural network ===\\nContinuous representations or embeddings of words are produced in recurrent neural network-based language models (known also as continuous space language models). Such continuous space embeddings help to alleviate the curse of dimensionality, which is the consequence of the number of possible sequences of words increasing exponentially with the size of the vocabulary, furtherly causing a'),\n",
       " Document(metadata={'title': 'Llama (language model)', 'summary': 'Llama (Large Language Model Meta AI, formerly stylized as LLaMA) is a family of autoregressive large language models (LLMs) released by Meta AI starting in February 2023. The latest version is Llama 3.2, released in September 2024.\\nModel weights for the first version of Llama were made available to the research community under a non-commercial license, and access was granted on a case-by-case basis. Unauthorized copies of the model were shared via BitTorrent. In response, Meta AI issued DMCA takedown requests against repositories sharing the link on GitHub. Subsequent versions of Llama were made accessible outside academia and released under licenses that permitted some commercial use. Llama models are trained at different parameter sizes, ranging between 1B and 405B. Originally, Llama was only available as a foundation model. Starting with Llama 2, Meta AI started releasing instruction fine-tuned versions alongside foundation models.\\nAlongside the release of Llama 3, Meta added virtual assistant features to Facebook and WhatsApp in select regions, and a standalone website. Both services use a Llama 3 model.', 'source': 'https://en.wikipedia.org/wiki/Llama_(language_model)'}, page_content='Llama (Large Language Model Meta AI, formerly stylized as LLaMA) is a family of autoregressive large language models (LLMs) released by Meta AI starting in February 2023. The latest version is Llama 3.2, released in September 2024.\\nModel weights for the first version of Llama were made available to the research community under a non-commercial license, and access was granted on a case-by-case basis. Unauthorized copies of the model were shared via BitTorrent. In response, Meta AI issued DMCA takedown requests against repositories sharing the link on GitHub. Subsequent versions of Llama were made accessible outside academia and released under licenses that permitted some commercial use. Llama models are trained at different parameter sizes, ranging between 1B and 405B. Originally, Llama was only available as a foundation model. Starting with Llama 2, Meta AI started releasing instruction fine-tuned versions alongside foundation models.\\nAlongside the release of Llama 3, Meta added virtual assistant features to Facebook and WhatsApp in select regions, and a standalone website. Both services use a Llama 3 model.'),\n",
       " Document(metadata={'title': 'Llama (language model)', 'summary': 'Llama (Large Language Model Meta AI, formerly stylized as LLaMA) is a family of autoregressive large language models (LLMs) released by Meta AI starting in February 2023. The latest version is Llama 3.2, released in September 2024.\\nModel weights for the first version of Llama were made available to the research community under a non-commercial license, and access was granted on a case-by-case basis. Unauthorized copies of the model were shared via BitTorrent. In response, Meta AI issued DMCA takedown requests against repositories sharing the link on GitHub. Subsequent versions of Llama were made accessible outside academia and released under licenses that permitted some commercial use. Llama models are trained at different parameter sizes, ranging between 1B and 405B. Originally, Llama was only available as a foundation model. Starting with Llama 2, Meta AI started releasing instruction fine-tuned versions alongside foundation models.\\nAlongside the release of Llama 3, Meta added virtual assistant features to Facebook and WhatsApp in select regions, and a standalone website. Both services use a Llama 3 model.', 'source': 'https://en.wikipedia.org/wiki/Llama_(language_model)'}, page_content='== Background ==\\nAfter the release of large language models such as GPT-3, a focus of research was up-scaling models which in some instances showed major increases in emergent capabilities. The release of ChatGPT and its surprise success caused an increase in attention to large language models.\\nCompared with other responses to ChatGPT, Meta\\'s Chief AI scientist Yann LeCun stated that large language models are best for aiding with writing.\\nAn empirical investigation of the Llama series was the scaling laws. It was observed that the Llama 3 models showed that when a model is trained on data that is more than the \"Chinchilla-optimal\" amount, the performance continues to scale log-linearly. For example, the Chinchilla-optimal dataset for Llama 3 8B is 200 billion tokens, but performance continued to scale log-linearly to the 75-times larger dataset of 15 trillion tokens.'),\n",
       " Document(metadata={'title': 'Llama (language model)', 'summary': 'Llama (Large Language Model Meta AI, formerly stylized as LLaMA) is a family of autoregressive large language models (LLMs) released by Meta AI starting in February 2023. The latest version is Llama 3.2, released in September 2024.\\nModel weights for the first version of Llama were made available to the research community under a non-commercial license, and access was granted on a case-by-case basis. Unauthorized copies of the model were shared via BitTorrent. In response, Meta AI issued DMCA takedown requests against repositories sharing the link on GitHub. Subsequent versions of Llama were made accessible outside academia and released under licenses that permitted some commercial use. Llama models are trained at different parameter sizes, ranging between 1B and 405B. Originally, Llama was only available as a foundation model. Starting with Llama 2, Meta AI started releasing instruction fine-tuned versions alongside foundation models.\\nAlongside the release of Llama 3, Meta added virtual assistant features to Facebook and WhatsApp in select regions, and a standalone website. Both services use a Llama 3 model.', 'source': 'https://en.wikipedia.org/wiki/Llama_(language_model)'}, page_content='== Initial release ==\\nLLaMA was announced on February 24, 2023, via a blog post and a paper describing the model\\'s training, architecture, and performance. The inference code used to run the model was publicly released under the open-source GPLv3 license. Access to the model\\'s weights was managed by an application process, with access to be granted \"on a case-by-case basis to academic researchers; those affiliated with organizations in government, civil society, and academia; and industry research laboratories around the world\".\\nLlama was trained on only publicly available information, and was trained at various model sizes, with the intention to make it more accessible to different hardware.\\nMeta AI reported the 13B parameter model performance on most NLP benchmarks exceeded that of the much larger GPT-3 (with 175B parameters), and the largest 65B model was competitive with state of the art models such as PaLM and Chinchilla.'),\n",
       " Document(metadata={'title': 'Llama (language model)', 'summary': 'Llama (Large Language Model Meta AI, formerly stylized as LLaMA) is a family of autoregressive large language models (LLMs) released by Meta AI starting in February 2023. The latest version is Llama 3.2, released in September 2024.\\nModel weights for the first version of Llama were made available to the research community under a non-commercial license, and access was granted on a case-by-case basis. Unauthorized copies of the model were shared via BitTorrent. In response, Meta AI issued DMCA takedown requests against repositories sharing the link on GitHub. Subsequent versions of Llama were made accessible outside academia and released under licenses that permitted some commercial use. Llama models are trained at different parameter sizes, ranging between 1B and 405B. Originally, Llama was only available as a foundation model. Starting with Llama 2, Meta AI started releasing instruction fine-tuned versions alongside foundation models.\\nAlongside the release of Llama 3, Meta added virtual assistant features to Facebook and WhatsApp in select regions, and a standalone website. Both services use a Llama 3 model.', 'source': 'https://en.wikipedia.org/wiki/Llama_(language_model)'}, page_content='=== Leak ===\\nOn March 3, 2023, a torrent containing LLaMA\\'s weights was uploaded, with a link to the torrent shared on the 4chan imageboard and subsequently spread through online AI communities. That same day, a pull request on the main LLaMA repository was opened, requesting to add the magnet link to the official documentation. On March 4, a pull request was opened to add links to HuggingFace repositories containing the model. On March 6, Meta filed takedown requests to remove the HuggingFace repositories linked in the pull request, characterizing it as \"unauthorized distribution\" of the model. HuggingFace complied with the requests. On March 20, Meta filed a DMCA takedown request for copyright infringement against a repository containing a script that downloaded LLaMA from a mirror, and GitHub complied the next day.\\nReactions to the leak varied. Some speculated that the model would be used for malicious purposes, such as more sophisticated spam. Some have celebrated the model\\'s accessibility, as well as the fact that smaller vers'),\n",
       " Document(metadata={'title': 'Claude (language model)', 'summary': 'Claude is a family of large language models developed by Anthropic. The first model was released in March 2023.\\nThe Claude 3 family, released in March 2024, consists of three models: Haiku optimized for speed, Sonnet balancing capabilities and performance, and Opus designed for complex reasoning tasks. These models can process both text and images, with Claude 3 Opus demonstrating enhanced capabilities in areas like mathematics, programming, and logical reasoning compared to previous versions.', 'source': 'https://en.wikipedia.org/wiki/Claude_(language_model)'}, page_content='Claude is a family of large language models developed by Anthropic. The first model was released in March 2023.\\nThe Claude 3 family, released in March 2024, consists of three models: Haiku optimized for speed, Sonnet balancing capabilities and performance, and Opus designed for complex reasoning tasks. These models can process both text and images, with Claude 3 Opus demonstrating enhanced capabilities in areas like mathematics, programming, and logical reasoning compared to previous versions.\\n\\n\\n== Training ==\\nClaude models are generative pre-trained transformers. They have been pre-trained to predict the next word in large amounts of text. Then, they have been fine-tuned, notably using constitutional AI and reinforcement learning from human feedback (RLHF).'),\n",
       " Document(metadata={'title': 'Claude (language model)', 'summary': 'Claude is a family of large language models developed by Anthropic. The first model was released in March 2023.\\nThe Claude 3 family, released in March 2024, consists of three models: Haiku optimized for speed, Sonnet balancing capabilities and performance, and Opus designed for complex reasoning tasks. These models can process both text and images, with Claude 3 Opus demonstrating enhanced capabilities in areas like mathematics, programming, and logical reasoning compared to previous versions.', 'source': 'https://en.wikipedia.org/wiki/Claude_(language_model)'}, page_content='=== Constitutional AI ===\\nConstitutional AI is an approach developed by Anthropic for training AI systems, particularly language models like Claude, to be harmless and helpful without relying on extensive human feedback. The method, detailed in the paper \"Constitutional AI: Harmlessness from AI Feedback\" involves two phases: supervised learning and reinforcement learning.\\nIn the supervised learning phase, the model generates responses to prompts, self-critiques these responses based on a set of guiding principles (a \"constitution\"), and revises the responses. Then the model is fine-tuned on these revised responses.\\nFor the reinforcement learning from AI feedback (RLAIF) phase, responses are generated, and an AI compares their compliance with the constitution. This dataset of AI feedback is used to train a preference model that evaluates responses based on how much they satisfy the constitution. Claude is then fine-tuned to align with this preference model. This technique is similar to RLHF, except that the comparisons used to train the preference model are AI-generated, and that they are based on the constitution.\\nThe \"constitution\" for Claude included 75 points, including sections from the UN Universal Declaration of Human Rights.\\n\\n\\n== Models ==\\nThe name Claude was notably inspired by Claude Shannon, a pioneer in artificial intelligence.'),\n",
       " Document(metadata={'title': 'Claude (language model)', 'summary': 'Claude is a family of large language models developed by Anthropic. The first model was released in March 2023.\\nThe Claude 3 family, released in March 2024, consists of three models: Haiku optimized for speed, Sonnet balancing capabilities and performance, and Opus designed for complex reasoning tasks. These models can process both text and images, with Claude 3 Opus demonstrating enhanced capabilities in areas like mathematics, programming, and logical reasoning compared to previous versions.', 'source': 'https://en.wikipedia.org/wiki/Claude_(language_model)'}, page_content=\"== Models ==\\nThe name Claude was notably inspired by Claude Shannon, a pioneer in artificial intelligence.\\n\\n\\n=== Claude ===\\nClaude was the initial version of Anthropic's language model released in March 2023, Claude demonstrated proficiency in various tasks but had certain limitations in coding, math, and reasoning capabilities. Anthropic partnered with companies like Notion (productivity software) and Quora (to help develop the Poe chatbot).\\n\\n\\n==== Claude Instant ====\\nClaude was released as two versions, Claude and Claude Instant, with Claude Instant being a faster, less expensive, and lighter version. Claude Instant has an input context length of 100,000 tokens (which corresponds to around 75,000 words).\\n\\n\\n=== Claude 2 ===\\nClaude 2 was the next major iteration of Claude, which was released in July 2023 and available to the general public, whereas the Claude 1 was only available to selected users approved by Anthropic.\\nClaude 2 expanded its context window from 9,000 tokens to 100,000 tokens. Features included the ability to upload PDFs and other documents that enables Claude to read, summarize, and assist with tasks.\"),\n",
       " Document(metadata={'title': 'Claude (language model)', 'summary': 'Claude is a family of large language models developed by Anthropic. The first model was released in March 2023.\\nThe Claude 3 family, released in March 2024, consists of three models: Haiku optimized for speed, Sonnet balancing capabilities and performance, and Opus designed for complex reasoning tasks. These models can process both text and images, with Claude 3 Opus demonstrating enhanced capabilities in areas like mathematics, programming, and logical reasoning compared to previous versions.', 'source': 'https://en.wikipedia.org/wiki/Claude_(language_model)'}, page_content='==== Claude 2.1 ====\\nClaude 2.1 doubled the number of tokens that the chatbot could handle, increasing it to a window of 200,000 tokens, which equals around 500 pages of written material.\\nAnthropic states that the new model is less likely to produce false statements compared to its predecessors.\\n\\n\\n=== Claude 3 ===\\nClaude 3 was released on March 14, 2024, with claims in the press release to have set new industry benchmarks across a wide range of cognitive tasks. The Claude 3 family includes three state-of-the-art models in ascending order of capability: Haiku, Sonnet, and Opus. The default version of Claude 3, Opus, has a context window of 200,000 tokens, but this is being expanded to 1 million for specific use cases.\\nClaude 3 drew attention for demonstrating an apparent ability to realize it is being artificially tested durin'),\n",
       " Document(metadata={'title': 'T5 (language model)', 'summary': 'T5 (Text-to-Text Transfer Transformer) is a series of large language models developed by Google AI introduced in 2019. Like the original Transformer model, T5 models are encoder-decoder Transformers, where the encoder processes the input text, and the decoder generates the output text.\\nT5 models are usually pretrained on a massive dataset of text and code, after which they can perform the text-based tasks that are similar to their pretrained tasks. They can also be finetuned to perform other tasks.\\nT5 models have been employed in various applications, including chatbots, machine translation systems, text summarization tools, code generation, and robotics.', 'source': 'https://en.wikipedia.org/wiki/T5_(language_model)'}, page_content='T5 (Text-to-Text Transfer Transformer) is a series of large language models developed by Google AI introduced in 2019. Like the original Transformer model, T5 models are encoder-decoder Transformers, where the encoder processes the input text, and the decoder generates the output text.\\nT5 models are usually pretrained on a massive dataset of text and code, after which they can perform the text-based tasks that are similar to their pretrained tasks. They can also be finetuned to perform other tasks.\\nT5 models have been employed in various applications, including chatbots, machine translation systems, text summarization tools, code generation, and robotics.\\n\\n\\n== Training ==\\nThe original T5 models are pre-trained on the Colossal Clean Crawled Corpus (C4), containing text and code scraped from the internet. This pre-training process enables the models to learn general language understanding and generation abilities. T5 models can then be fine-tuned on specific downstream tasks, adapting their knowledge to perform well in various applications.\\nThe T5 models were pretrained on many tasks, all in the format of <input text> -> <output text>.\\n\\nSome examples are:'),\n",
       " Document(metadata={'title': 'T5 (language model)', 'summary': 'T5 (Text-to-Text Transfer Transformer) is a series of large language models developed by Google AI introduced in 2019. Like the original Transformer model, T5 models are encoder-decoder Transformers, where the encoder processes the input text, and the decoder generates the output text.\\nT5 models are usually pretrained on a massive dataset of text and code, after which they can perform the text-based tasks that are similar to their pretrained tasks. They can also be finetuned to perform other tasks.\\nT5 models have been employed in various applications, including chatbots, machine translation systems, text summarization tools, code generation, and robotics.', 'source': 'https://en.wikipedia.org/wiki/T5_(language_model)'}, page_content='Some examples are:\\n\\nrestoring corrupted text: Thank you <X> me to your party <Y> week. -> <X> for inviting <Y> last <Z>, where the <Z> means \"end of output\", and the  <X> and  <Y> denote blanks to be filled, called \"sentinels\" in the original report.\\ntranslation: translate English to German: That is good. -> Das ist gut..\\njudging the grammatical acceptability of a sentence (CoLA sentence): The course is jumping well. -> not acceptable .\\n\\n\\n== Architecture ==\\n\\nThe T5 series encompasses several models with varying sizes and capabilities, all encoder-decoder Transformers, where the encoder processes the input text, and the decoder generates the output text.\\nThese models are often distinguished by their parameter count, which indicates the complexity and potential capacity of the model. The original paper reported the following 5 models:\\n\\n*The encoder and the decoder have the same shape. So for example, the T5-small has 6 layers in the encoder and 6 layers in the decoder.\\nIn the above table,'),\n",
       " Document(metadata={'title': 'T5 (language model)', 'summary': 'T5 (Text-to-Text Transfer Transformer) is a series of large language models developed by Google AI introduced in 2019. Like the original Transformer model, T5 models are encoder-decoder Transformers, where the encoder processes the input text, and the decoder generates the output text.\\nT5 models are usually pretrained on a massive dataset of text and code, after which they can perform the text-based tasks that are similar to their pretrained tasks. They can also be finetuned to perform other tasks.\\nT5 models have been employed in various applications, including chatbots, machine translation systems, text summarization tools, code generation, and robotics.', 'source': 'https://en.wikipedia.org/wiki/T5_(language_model)'}, page_content='*The encoder and the decoder have the same shape. So for example, the T5-small has 6 layers in the encoder and 6 layers in the decoder.\\nIn the above table,\\n\\n  \\n    \\n      \\n        \\n          n\\n          \\n            layer\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle n_{\\\\text{layer}}}\\n  \\n: Number of layers in the encoder; also, number of layers in the decoder. They always have the same number of layers.'),\n",
       " Document(metadata={'title': 'T5 (language model)', 'summary': 'T5 (Text-to-Text Transfer Transformer) is a series of large language models developed by Google AI introduced in 2019. Like the original Transformer model, T5 models are encoder-decoder Transformers, where the encoder processes the input text, and the decoder generates the output text.\\nT5 models are usually pretrained on a massive dataset of text and code, after which they can perform the text-based tasks that are similar to their pretrained tasks. They can also be finetuned to perform other tasks.\\nT5 models have been employed in various applications, including chatbots, machine translation systems, text summarization tools, code generation, and robotics.', 'source': 'https://en.wikipedia.org/wiki/T5_(language_model)'}, page_content='n\\n          \\n            head\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle n_{\\\\text{head}}}\\n  \\n: Number of attention heads in each attention block.\\n\\n  \\n    \\n      \\n        \\n          d\\n          \\n            model\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle d_{\\\\text{model}}}\\n  \\n: Dimension of the embedding vectors.'),\n",
       " Document(metadata={'title': 'T5 (language model)', 'summary': 'T5 (Text-to-Text Transfer Transformer) is a series of large language models developed by Google AI introduced in 2019. Like the original Transformer model, T5 models are encoder-decoder Transformers, where the encoder processes the input text, and the decoder generates the output text.\\nT5 models are usually pretrained on a massive dataset of text and code, after which they can perform the text-based tasks that are similar to their pretrained tasks. They can also be finetuned to perform other tasks.\\nT5 models have been employed in various applications, including chatbots, machine translation systems, text summarization tools, code generation, and robotics.', 'source': 'https://en.wikipedia.org/wiki/T5_(language_model)'}, page_content='d\\n          \\n            ff\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle d_{\\\\text{ff}}}\\n  \\n: Dimension of the feedforward network within each encoder and decoder layer.'),\n",
       " Document(metadata={'title': 'T5 (language model)', 'summary': 'T5 (Text-to-Text Transfer Transformer) is a series of large language models developed by Google AI introduced in 2019. Like the original Transformer model, T5 models are encoder-decoder Transformers, where the encoder processes the input text, and the decoder generates the output text.\\nT5 models are usually pretrained on a massive dataset of text and code, after which they can perform the text-based tasks that are similar to their pretrained tasks. They can also be finetuned to perform other tasks.\\nT5 models have been employed in various applications, including chatbots, machine translation systems, text summarization tools, code generation, and robotics.', 'source': 'https://en.wikipedia.org/wiki/T5_(language_model)'}, page_content='d\\n          \\n            kv\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle d_{\\\\text{kv}}}\\n  \\n: Dimension of the key and value vectors used in the self-attention mechanism.\\nNote that unlike typical Transformers, the 3B and 11B models do not satisfy \\n  \\n    \\n      \\n        \\n          d\\n          \\n            model\\n          \\n        \\n        =\\n        \\n          d\\n          \\n            kv'),\n",
       " Document(metadata={'title': 'T5 (language model)', 'summary': 'T5 (Text-to-Text Transfer Transformer) is a series of large language models developed by Google AI introduced in 2019. Like the original Transformer model, T5 models are encoder-decoder Transformers, where the encoder processes the input text, and the decoder generates the output text.\\nT5 models are usually pretrained on a massive dataset of text and code, after which they can perform the text-based tasks that are similar to their pretrained tasks. They can also be finetuned to perform other tasks.\\nT5 models have been employed in various applications, including chatbots, machine translation systems, text summarization tools, code generation, and robotics.', 'source': 'https://en.wikipedia.org/wiki/T5_(language_model)'}, page_content='kv\\n          \\n        \\n        \\n          n\\n          \\n            head\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle d_{\\\\text{model}}=d_{\\\\text{kv}}n_{\\\\text{head}}}\\n  \\n.\\nCompared to the original Transformer, it uses a few minor modifications: layer normalization with no additive bias; placing the layer normalization outside the residual path; relative positional embedding.\\nFor all experiments, they used a WordPiece tokenizer, with vocabulary size 32,000. The tokenizer is shared across both the input and output of each model. It was trained on a mixture of English, German, Fre'),\n",
       " Document(metadata={'title': 'Generative pre-trained transformer', 'summary': 'A generative pre-trained transformer (GPT) is a type of large language model (LLM) and a prominent framework for generative artificial intelligence. It is an artificial neural network that is used in natural language processing by machines. It is based on the transformer deep learning architecture, pre-trained on large data sets of unlabeled text, and able to generate novel human-like content. As of 2023, most LLMs had these characteristics and are sometimes referred to broadly as GPTs.\\nThe first GPT was introduced in 2018 by OpenAI. OpenAI has released significant GPT foundation models that have been sequentially numbered, to comprise its \"GPT-n\" series. Each of these was significantly more capable than the previous, due to increased size (number of trainable parameters) and training. The most recent of these, GPT-4o, was released in May 2024. Such models have been the basis for their more task-specific GPT systems, including models fine-tuned for instruction following—which in turn power the ChatGPT chatbot service.\\nThe term \"GPT\" is also used in the names and descriptions of such models developed by others. For example, other GPT foundation models include a series of models created by EleutherAI, and seven models created by Cerebras in 2023. Companies in different industries have developed task-specific GPTs in their respective fields, such as Salesforce\\'s \"EinsteinGPT\" (for CRM) and Bloomberg\\'s \"BloombergGPT\" (for finance).\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Generative_pre-trained_transformer'}, page_content='A generative pre-trained transformer (GPT) is a type of large language model (LLM) and a prominent framework for generative artificial intelligence. It is an artificial neural network that is used in natural language processing by machines. It is based on the transformer deep learning architecture, pre-trained on large data sets of unlabeled text, and able to generate novel human-like content. As of 2023, most LLMs had these characteristics and are sometimes referred to broadly as GPTs.\\nThe first GPT was introduced in 2018 by OpenAI. OpenAI has released significant GPT foundation models that have been sequentially numbered, to comprise its \"GPT-n\" series. Each of these was significantly more capable than the previous, due to increased size (number of trainable parameters) and training. The most recent of these, GPT-4o, was released in May 2024. Such models have been the basis for their more task-specific GPT systems, including models fine-tuned for instruction following—which in turn power the ChatGPT chatbot service.'),\n",
       " Document(metadata={'title': 'Generative pre-trained transformer', 'summary': 'A generative pre-trained transformer (GPT) is a type of large language model (LLM) and a prominent framework for generative artificial intelligence. It is an artificial neural network that is used in natural language processing by machines. It is based on the transformer deep learning architecture, pre-trained on large data sets of unlabeled text, and able to generate novel human-like content. As of 2023, most LLMs had these characteristics and are sometimes referred to broadly as GPTs.\\nThe first GPT was introduced in 2018 by OpenAI. OpenAI has released significant GPT foundation models that have been sequentially numbered, to comprise its \"GPT-n\" series. Each of these was significantly more capable than the previous, due to increased size (number of trainable parameters) and training. The most recent of these, GPT-4o, was released in May 2024. Such models have been the basis for their more task-specific GPT systems, including models fine-tuned for instruction following—which in turn power the ChatGPT chatbot service.\\nThe term \"GPT\" is also used in the names and descriptions of such models developed by others. For example, other GPT foundation models include a series of models created by EleutherAI, and seven models created by Cerebras in 2023. Companies in different industries have developed task-specific GPTs in their respective fields, such as Salesforce\\'s \"EinsteinGPT\" (for CRM) and Bloomberg\\'s \"BloombergGPT\" (for finance).\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Generative_pre-trained_transformer'}, page_content='The term \"GPT\" is also used in the names and descriptions of such models developed by others. For example, other GPT foundation models include a series of models created by EleutherAI, and seven models created by Cerebras in 2023. Companies in different industries have developed task-specific GPTs in their respective fields, such as Salesforce\\'s \"EinsteinGPT\" (for CRM) and Bloomberg\\'s \"BloombergGPT\" (for finance).'),\n",
       " Document(metadata={'title': 'Generative pre-trained transformer', 'summary': 'A generative pre-trained transformer (GPT) is a type of large language model (LLM) and a prominent framework for generative artificial intelligence. It is an artificial neural network that is used in natural language processing by machines. It is based on the transformer deep learning architecture, pre-trained on large data sets of unlabeled text, and able to generate novel human-like content. As of 2023, most LLMs had these characteristics and are sometimes referred to broadly as GPTs.\\nThe first GPT was introduced in 2018 by OpenAI. OpenAI has released significant GPT foundation models that have been sequentially numbered, to comprise its \"GPT-n\" series. Each of these was significantly more capable than the previous, due to increased size (number of trainable parameters) and training. The most recent of these, GPT-4o, was released in May 2024. Such models have been the basis for their more task-specific GPT systems, including models fine-tuned for instruction following—which in turn power the ChatGPT chatbot service.\\nThe term \"GPT\" is also used in the names and descriptions of such models developed by others. For example, other GPT foundation models include a series of models created by EleutherAI, and seven models created by Cerebras in 2023. Companies in different industries have developed task-specific GPTs in their respective fields, such as Salesforce\\'s \"EinsteinGPT\" (for CRM) and Bloomberg\\'s \"BloombergGPT\" (for finance).\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Generative_pre-trained_transformer'}, page_content='== History ==\\n\\n\\n=== Initial developments ===\\nGenerative pretraining (GP) was a long-established concept in machine learning applications. It was originally used as a form of semi-supervised learning, as the model is trained first on an unlabelled dataset (pretraining step) by learning to generate datapoints in the dataset, and then it is trained to classify a labelled dataset. \\nThere were mainly 3 types of early GP. The hidden Markov models learn a generative model of sequences for downstream applications. For example, in speech recognition, a trained HMM infers the most likely hidden sequence for a speech signal, and the hidden sequence is taken as the phonemes of the speech signal. These were developed in the 1970s and became widely applied in speech recognition in the 1980s.\\nThe compressors learn to compress data such as images and textual sequences, and the compressed data serves as a good representation for downstream applications such as facial recognition. The autoencoders similarly learn a latent representation of data for later downstream applications such as speech recognition. The connection between autoencoders and algorithmic compressors was noted in 1993.'),\n",
       " Document(metadata={'title': 'Generative pre-trained transformer', 'summary': 'A generative pre-trained transformer (GPT) is a type of large language model (LLM) and a prominent framework for generative artificial intelligence. It is an artificial neural network that is used in natural language processing by machines. It is based on the transformer deep learning architecture, pre-trained on large data sets of unlabeled text, and able to generate novel human-like content. As of 2023, most LLMs had these characteristics and are sometimes referred to broadly as GPTs.\\nThe first GPT was introduced in 2018 by OpenAI. OpenAI has released significant GPT foundation models that have been sequentially numbered, to comprise its \"GPT-n\" series. Each of these was significantly more capable than the previous, due to increased size (number of trainable parameters) and training. The most recent of these, GPT-4o, was released in May 2024. Such models have been the basis for their more task-specific GPT systems, including models fine-tuned for instruction following—which in turn power the ChatGPT chatbot service.\\nThe term \"GPT\" is also used in the names and descriptions of such models developed by others. For example, other GPT foundation models include a series of models created by EleutherAI, and seven models created by Cerebras in 2023. Companies in different industries have developed task-specific GPTs in their respective fields, such as Salesforce\\'s \"EinsteinGPT\" (for CRM) and Bloomberg\\'s \"BloombergGPT\" (for finance).\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Generative_pre-trained_transformer'}, page_content='During the 2010s, the problem of machine translation was solved by recurrent neural networks, with attention mechanism added. This was optimized into the transformer architecture, published by Google researchers in Attention Is All You Need (2017). That development led to the emergence of large language models such as BERT (2018) which was a pre-trained transformer (PT) but not designed to be generative (BERT was an \"encoder-only\" model). Also in 2018, OpenAI published Improving Language Understanding by Generative Pre-Training, which introduced GPT-1, the first in its GPT series.\\nPreviously in 2017, some of the authors who would later work on GPT-1 worked on generative pre-training of language with LSTM, which resulted in a model that could represent text with vectors that could easily be fine-tuned for downstream applications.\\nPrior to transformer-based architectures, the best-performing neural NLP (natural language processing) models commonly employed supervised learning from large amounts of manually-labeled data. The reliance on supervised learning limited their use on datasets that were not well-annotated, and also made it prohibitively expensive and time-consuming to train extremely large language models.\\nThe semi-supervised approach OpenAI employed to make a large-scale generative system—and was first to do with a transformer m'),\n",
       " Document(metadata={'title': 'Chinchilla (language model)', 'summary': 'Chinchilla is a family of large language models (LLMs) developed by the research team at Google DeepMind, presented in March 2022.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Chinchilla_(language_model)'}, page_content='Chinchilla is a family of large language models (LLMs) developed by the research team at Google DeepMind, presented in March 2022.'),\n",
       " Document(metadata={'title': 'Chinchilla (language model)', 'summary': 'Chinchilla is a family of large language models (LLMs) developed by the research team at Google DeepMind, presented in March 2022.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Chinchilla_(language_model)'}, page_content='== Models ==\\nIt is named \"chinchilla\" because it is a further development over a previous model family named Gopher. Both model families were trained in order to investigate the scaling laws of large language models. \\nIt claimed to outperform GPT-3. It considerably simplifies downstream utilization because it requires much less computer power for inference and fine-tuning. Based on the training of previously employed language models, it has been determined that if one doubles the model size, one must also have twice the number of training tokens. This hypothesis has been used to train Chinchilla by DeepMind. Similar to Gopher in terms of cost, Chinchilla has 70B parameters and four times as much data. \\nChinchilla has an average accuracy of 67.5% on the Measuring Massive Multitask Language Understanding (MMLU) benchmark, which is 7% higher than Gopher\\'s performance. Chinchilla was still in the testing phase as of January 12, 2023.\\nChinchilla contributes to developing an effective training paradigm for large autoregressive language models with limited compute resources. The Chinchilla team recommends that the number of training tokens is twice for every model size doubling, meaning that using larger, higher-quality training datasets can lead to better results on downstream tasks.\\nIt has been used for the Flamingo vision-language model.'),\n",
       " Document(metadata={'title': 'Chinchilla (language model)', 'summary': 'Chinchilla is a family of large language models (LLMs) developed by the research team at Google DeepMind, presented in March 2022.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Chinchilla_(language_model)'}, page_content='== Architecture ==\\nBoth the Gopher family and Chinchilla family are families of transformer models. \\nIn particular, they are essentially the same as GPT-2, with different sizes and minor modifications. Gopher family uses RMSNorm instead of LayerNorm; relative positional encoding rather than absolute positional encoding. The Chinchilla family is the same as the Gopher family, but trained with AdamW instead of Adam optimizer.\\nThe Gopher family contains six models of increasing size, from 44 million parameters to 280 billion parameters. They refer to the largest one as \"Gopher\" by default. Similar naming conventions apply for the Chinchilla family.\\nTable 1 of  shows the entire Gopher family:\\n\\nTable 4 of  compares the 70-billion-parameter Chinchilla with Gopher 280B.\\n\\n\\n== See also ==\\nLaMDA\\n\\n\\n== References =='),\n",
       " Document(metadata={'title': 'Modeling language', 'summary': 'A modeling language is any artificial language that can be used to express data, information or knowledge or systems in a structure that is defined by a consistent set of rules. The rules are used for interpretation of the meaning of components in the structure of a programming language.', 'source': 'https://en.wikipedia.org/wiki/Modeling_language'}, page_content=\"A modeling language is any artificial language that can be used to express data, information or knowledge or systems in a structure that is defined by a consistent set of rules. The rules are used for interpretation of the meaning of components in the structure of a programming language.\\n\\n\\n== Overview ==\\nA modeling language can be graphical or textual.\\n\\nGraphical modeling languages use a diagram technique with named symbols that represent concepts and lines that connect the symbols and represent relationships and various other graphical notation to represent constraints.\\nTextual modeling languages may use standardized keywords accompanied by parameters or natural language terms and phrases to make computer-interpretable expressions.\\nAn example of a graphical modeling language and a corresponding textual modeling language is EXPRESS.\\nNot all modeling languages are executable, and for those that are, the use of them doesn't necessarily mean that programmers are no longer required. On the contrary, executable modeling languages are intended to amplify the productivity of skilled programmers, so that they can address more challenging problems, such as parallel computing and distributed systems.\\nA large number of modeling languages appear in the literature.\\n\\n\\n== Type of modeling languages ==\\n\\n\\n=== Graphical types ===\\nExample of graphical modeling languages in the field of computer science, project management and systems engineering:\"),\n",
       " Document(metadata={'title': 'Modeling language', 'summary': 'A modeling language is any artificial language that can be used to express data, information or knowledge or systems in a structure that is defined by a consistent set of rules. The rules are used for interpretation of the meaning of components in the structure of a programming language.', 'source': 'https://en.wikipedia.org/wiki/Modeling_language'}, page_content='Behavior Trees are a formal, graphical modeling language used primarily in systems and software engineering. Commonly used to unambiguously represent the hundreds or even thousands of natural language requirements that are typically used to express the stakeholder needs for a large-scale software-integrated system.\\nBusiness Process Modeling Notation (BPMN, and the XML form BPML) is an example of a Process Modeling language.\\nC-K theory consists of a modeling language for design processes.\\nDRAKON is a general-purpose algorithmic modeling language for specifying software-intensive systems, a schematic representation of an algorithm or a stepwise process, and a family of programming languages.\\nEXPRESS and EXPRESS-G (ISO 10303-11) is an international standard general-purpose data modeling language.\\nExtended Enterprise Modeling Language (EEML) is commonly used for business process modeling across a number of layers.\\nFlowchart is a schematic representation of an algorithm or a stepwise process.\\nFundamental Modeling Concepts (FMC) modeling language for software-intensive systems.\\nIDEF is a family of modeling languages, which include IDEF0 for functional modeling, IDEF1X for information modeling, IDEF3 for business process modeling, IDEF4 for Object-Oriented Design and IDEF5 for modeling ontologies.'),\n",
       " Document(metadata={'title': 'Modeling language', 'summary': 'A modeling language is any artificial language that can be used to express data, information or knowledge or systems in a structure that is defined by a consistent set of rules. The rules are used for interpretation of the meaning of components in the structure of a programming language.', 'source': 'https://en.wikipedia.org/wiki/Modeling_language'}, page_content=\"Jackson Structured Programming (JSP) is a method for structured programming based on correspondences between data stream structure and program structure.\\nLePUS3 is an object-oriented visual Design Description Language and a formal specification language that is suitable primarily for modeling large object-oriented (Java, C++, C#) programs and design patterns.\\nLifecycle Modeling Language is an open-standard language for systems engineering that supports the full system lifecycle: conceptual, utilization, support and retirement stages.\\nObject-Role Modeling (ORM) in the field of software engineering is a method for conceptual modeling, and can be used as a tool for information and rules analysis.\\nPetri nets use variations on exactly one diagramming technique and topology, namely the bipartite graph.  The simplicity of its basic user interface easily enabled extensive tool support over the years, particularly in the areas of model checking, graphically oriented simulation, and software verification.\\nSouthbeach Notation is a visual modeling language used to describe situations in terms of agents that are considered useful or harmful from the modeler's perspective. The notation shows how the agents interact with each othe\"),\n",
       " Document(metadata={'title': 'BERT (language model)', 'summary': 'Bidirectional encoder representations from transformers (BERT) is a language model introduced in October 2018 by researchers at Google. It learns to represent text as a sequence of vectors using self-supervised learning. It uses the encoder-only transformer architecture. It is notable for its dramatic improvement over previous state-of-the-art models, and as an early example of a large language model. As of 2020, BERT is a ubiquitous baseline in natural language processing (NLP) experiments. \\nBERT is trained by masked token prediction and next sentence prediction. As a result of this training process, BERT learns contextual, latent representations of tokens in their context, similar to ELMo and GPT-2. It found applications for many natural language processing tasks, such as coreference resolution and polysemy resolution. It is an evolutionary step over ELMo, and spawned the study of \"BERTology\", which attempts to interpret what is learned by BERT.\\nBERT was originally implemented in the English language at two model sizes, BERTBASE (110 million parameters) and BERTLARGE (340 million parameters). Both were trained on the Toronto BookCorpus (800M words) and English Wikipedia  (2,500M words). The weights were released on GitHub. On March 11, 2020, 24 smaller models were released, the smallest being BERTTINY with just 4 million parameters.', 'source': 'https://en.wikipedia.org/wiki/BERT_(language_model)'}, page_content='Bidirectional encoder representations from transformers (BERT) is a language model introduced in October 2018 by researchers at Google. It learns to represent text as a sequence of vectors using self-supervised learning. It uses the encoder-only transformer architecture. It is notable for its dramatic improvement over previous state-of-the-art models, and as an early example of a large language model. As of 2020, BERT is a ubiquitous baseline in natural language processing (NLP) experiments. \\nBERT is trained by masked token prediction and next sentence prediction. As a result of this training process, BERT learns contextual, latent representations of tokens in their context, similar to ELMo and GPT-2. It found applications for many natural language processing tasks, such as coreference resolution and polysemy resolution. It is an evolutionary step over ELMo, and spawned the study of \"BERTology\", which attempts to interpret what is learned by BERT.\\nBERT was originally implemented in the English language at two model sizes, BERTBASE (110 million parameters) and BERTLARGE (340 million parameters). Both were trained on the Toronto BookCorpus (800M words) and English Wikipedia  (2,500M words). The weights were released on GitHub. On March 11, 2020, 24 smaller models were released, the smallest being BERTTINY with just 4 million parameters.\\n\\n\\n== Architecture =='),\n",
       " Document(metadata={'title': 'BERT (language model)', 'summary': 'Bidirectional encoder representations from transformers (BERT) is a language model introduced in October 2018 by researchers at Google. It learns to represent text as a sequence of vectors using self-supervised learning. It uses the encoder-only transformer architecture. It is notable for its dramatic improvement over previous state-of-the-art models, and as an early example of a large language model. As of 2020, BERT is a ubiquitous baseline in natural language processing (NLP) experiments. \\nBERT is trained by masked token prediction and next sentence prediction. As a result of this training process, BERT learns contextual, latent representations of tokens in their context, similar to ELMo and GPT-2. It found applications for many natural language processing tasks, such as coreference resolution and polysemy resolution. It is an evolutionary step over ELMo, and spawned the study of \"BERTology\", which attempts to interpret what is learned by BERT.\\nBERT was originally implemented in the English language at two model sizes, BERTBASE (110 million parameters) and BERTLARGE (340 million parameters). Both were trained on the Toronto BookCorpus (800M words) and English Wikipedia  (2,500M words). The weights were released on GitHub. On March 11, 2020, 24 smaller models were released, the smallest being BERTTINY with just 4 million parameters.', 'source': 'https://en.wikipedia.org/wiki/BERT_(language_model)'}, page_content='== Architecture ==\\n\\nBERT is an \"encoder-only\" transformer architecture. At a high level, BERT consists of 4 modules: \\n\\nTokenizer: This module converts a piece of English text into a sequence of integers (\"tokens\").\\nEmbedding: This module converts the sequence of tokens into an array of real-valued vectors representing the tokens. It represents the conversion of discrete token types into a lower-dimensional Euclidean space.\\nEncoder: a stack of Transformer blocks with self-attention, but without causal masking.\\nTask head: This module converts the final representation vectors into one-hot encoded tokens again by producing a predicted probability distribution over the token types. It can be viewed as a simple decoder, decoding the latent representation into token types, or as an \"un-embedding layer\".\\nThe task head is necessary for pre-training, but it is often unnecessary for so-called \"downstream tasks,\" such as question answering or sentiment classification. Instead, one removes the task head and replaces it with a newly initialized module suited for the task, and finetune the new module. The latent vector representation of the model is directly fed into this new module, allowing for sample-efficient transfer learning.'),\n",
       " Document(metadata={'title': 'BERT (language model)', 'summary': 'Bidirectional encoder representations from transformers (BERT) is a language model introduced in October 2018 by researchers at Google. It learns to represent text as a sequence of vectors using self-supervised learning. It uses the encoder-only transformer architecture. It is notable for its dramatic improvement over previous state-of-the-art models, and as an early example of a large language model. As of 2020, BERT is a ubiquitous baseline in natural language processing (NLP) experiments. \\nBERT is trained by masked token prediction and next sentence prediction. As a result of this training process, BERT learns contextual, latent representations of tokens in their context, similar to ELMo and GPT-2. It found applications for many natural language processing tasks, such as coreference resolution and polysemy resolution. It is an evolutionary step over ELMo, and spawned the study of \"BERTology\", which attempts to interpret what is learned by BERT.\\nBERT was originally implemented in the English language at two model sizes, BERTBASE (110 million parameters) and BERTLARGE (340 million parameters). Both were trained on the Toronto BookCorpus (800M words) and English Wikipedia  (2,500M words). The weights were released on GitHub. On March 11, 2020, 24 smaller models were released, the smallest being BERTTINY with just 4 million parameters.', 'source': 'https://en.wikipedia.org/wiki/BERT_(language_model)'}, page_content='=== Embedding ===\\nThis section describes the embedding used by BERTBASE. The other one, BERTLARGE, is similar, just larger.\\nThe tokenizer of BERT is WordPiece, which is a sub-word strategy like byte pair encoding. Its vocabulary size is 30,000, and any token not appearing in its vocabulary is replaced by [UNK] (\"unknown\"). \\n\\nThe first layer is the embedding layer, which contains three components: token type embeddings, position embeddings, and segment type embeddings.'),\n",
       " Document(metadata={'title': 'BERT (language model)', 'summary': 'Bidirectional encoder representations from transformers (BERT) is a language model introduced in October 2018 by researchers at Google. It learns to represent text as a sequence of vectors using self-supervised learning. It uses the encoder-only transformer architecture. It is notable for its dramatic improvement over previous state-of-the-art models, and as an early example of a large language model. As of 2020, BERT is a ubiquitous baseline in natural language processing (NLP) experiments. \\nBERT is trained by masked token prediction and next sentence prediction. As a result of this training process, BERT learns contextual, latent representations of tokens in their context, similar to ELMo and GPT-2. It found applications for many natural language processing tasks, such as coreference resolution and polysemy resolution. It is an evolutionary step over ELMo, and spawned the study of \"BERTology\", which attempts to interpret what is learned by BERT.\\nBERT was originally implemented in the English language at two model sizes, BERTBASE (110 million parameters) and BERTLARGE (340 million parameters). Both were trained on the Toronto BookCorpus (800M words) and English Wikipedia  (2,500M words). The weights were released on GitHub. On March 11, 2020, 24 smaller models were released, the smallest being BERTTINY with just 4 million parameters.', 'source': 'https://en.wikipedia.org/wiki/BERT_(language_model)'}, page_content=\"The first layer is the embedding layer, which contains three components: token type embeddings, position embeddings, and segment type embeddings. \\n\\nToken type: The token type is a standard embedding layer, translating a one-hot vector into a dense vector based on its token type.\\nPosition: The position embeddings are based on a token's position in the sequence. BERT uses absolute position embeddings, where each position in sequence is mapped to a real-valued vector. Each dimension of the vector consists of a sinusoidal function that takes the position in the sequence as input.\\nSegment type: Using a vocabulary of just 0 or 1, this embedding layer produces a dense vector based on whether the token belongs to the first or second text segment in that input. In other words, type-1 tokens are all tokens that appear after the [SEP] special token. All prior tokens are type-0.\\nThe three embedding vectors are added together representing the initial token representation as a function of these three pieces of information. After embedding, the vector representation is norm\"),\n",
       " Document(metadata={'title': 'Foundation model', 'summary': \"A foundation model, also known as large AI model, is a machine learning or deep learning model that is trained on vast datasets so it can be applied across a wide range of use cases. Generative AI applications like Large Language Models are often examples of foundation models.\\nBuilding foundation models is often highly resource-intensive, with the most expensive models costing hundreds of millions of dollars to pay for the underlying data and compute required. In contrast, adapting an existing foundation model for a specific task or using it directly is far less costly.\\nEarly examples of foundation models are language models (LMs) like OpenAI's GPT series and Google's BERT. Beyond text, foundation models have been developed across a range of modalities—including DALL-E and Flamingo for images, MusicGen for music, and RT-2 for robotic control. Foundation models are also being developed for fields like astronomy, radiology, genomics, music, coding, times-series forecasting, mathematics, and chemistry.\\n\\n\", 'source': 'https://en.wikipedia.org/wiki/Foundation_model'}, page_content=\"A foundation model, also known as large AI model, is a machine learning or deep learning model that is trained on vast datasets so it can be applied across a wide range of use cases. Generative AI applications like Large Language Models are often examples of foundation models.\\nBuilding foundation models is often highly resource-intensive, with the most expensive models costing hundreds of millions of dollars to pay for the underlying data and compute required. In contrast, adapting an existing foundation model for a specific task or using it directly is far less costly.\\nEarly examples of foundation models are language models (LMs) like OpenAI's GPT series and Google's BERT. Beyond text, foundation models have been developed across a range of modalities—including DALL-E and Flamingo for images, MusicGen for music, and RT-2 for robotic control. Foundation models are also being developed for fields like astronomy, radiology, genomics, music, coding, times-series forecasting, mathematics, and chemistry.\"),\n",
       " Document(metadata={'title': 'Foundation model', 'summary': \"A foundation model, also known as large AI model, is a machine learning or deep learning model that is trained on vast datasets so it can be applied across a wide range of use cases. Generative AI applications like Large Language Models are often examples of foundation models.\\nBuilding foundation models is often highly resource-intensive, with the most expensive models costing hundreds of millions of dollars to pay for the underlying data and compute required. In contrast, adapting an existing foundation model for a specific task or using it directly is far less costly.\\nEarly examples of foundation models are language models (LMs) like OpenAI's GPT series and Google's BERT. Beyond text, foundation models have been developed across a range of modalities—including DALL-E and Flamingo for images, MusicGen for music, and RT-2 for robotic control. Foundation models are also being developed for fields like astronomy, radiology, genomics, music, coding, times-series forecasting, mathematics, and chemistry.\\n\\n\", 'source': 'https://en.wikipedia.org/wiki/Foundation_model'}, page_content='== Definitions ==\\nThe Stanford Institute for Human-Centered Artificial Intelligence\\'s (HAI) Center for Research on Foundation Models (CRFM) coined the term \"foundation model\" in August 2021 to mean \"any model that is trained on broad data (generally using self-supervision at scale) that can be adapted (e.g., fine-tuned) to a wide range of downstream tasks\". This was based on their observation that preexisting terms, while overlapping, were not adequate, stating that \"\\'(large) language model\\' was too narrow given [the] focus is not only language; \\'self-supervised model\\' was too specific to the training objective; and \\'pretrained model\\' suggested that the noteworthy action all happened after \\'pretraining.\" The term \"foundation model\" was chosen over \"foundational model\" because \"foundational\" implies that these models provide fundamental principles in a way that \"foundation\" does not.\\nAs governments regulate foundation models, new legal definitions have emerged.'),\n",
       " Document(metadata={'title': 'Foundation model', 'summary': \"A foundation model, also known as large AI model, is a machine learning or deep learning model that is trained on vast datasets so it can be applied across a wide range of use cases. Generative AI applications like Large Language Models are often examples of foundation models.\\nBuilding foundation models is often highly resource-intensive, with the most expensive models costing hundreds of millions of dollars to pay for the underlying data and compute required. In contrast, adapting an existing foundation model for a specific task or using it directly is far less costly.\\nEarly examples of foundation models are language models (LMs) like OpenAI's GPT series and Google's BERT. Beyond text, foundation models have been developed across a range of modalities—including DALL-E and Flamingo for images, MusicGen for music, and RT-2 for robotic control. Foundation models are also being developed for fields like astronomy, radiology, genomics, music, coding, times-series forecasting, mathematics, and chemistry.\\n\\n\", 'source': 'https://en.wikipedia.org/wiki/Foundation_model'}, page_content='In the United States, the Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence defines a foundation model as \"an AI model that is trained on broad data; generally uses self-supervision; contains at least tens of billions of parameters; is applicable across a wide range of contexts\".\\nIn the United States, the proposed AI Foundation Model Transparency Act of 2023 by House Representatives Don Beyer (D, VA) and Anna Eshoo (D, CA) defines a foundation model as \"an artificial intelligence model trained on broad data, generally uses self supervision, generally contains at least 1,000,000,000 parameters, is applicable across a wide range of contexts, and exhibits, or could be easily modified to exhibit, high levels of performance at tasks that could pose a serious risk to security, national economic security, national public health or safety, or any combination of those matters.\"\\nIn the European Union, the European Parliament\\'s negotiated position on the E.U. AI Act defines a foundation model as an \"AI model that is trained on broad data at scale, is designed for generality of output, and can be adapted to a wide range of distinctive tasks\".\\nIn the United Kingdom, the Competition and Markets Authority\\'s AI Foundation Models: Initial Report  defines foundations model as \"a type of AI technology that are trained on vast amounts of data that can be adapted to a wide range of tasks and operations.\"'),\n",
       " Document(metadata={'title': 'Foundation model', 'summary': \"A foundation model, also known as large AI model, is a machine learning or deep learning model that is trained on vast datasets so it can be applied across a wide range of use cases. Generative AI applications like Large Language Models are often examples of foundation models.\\nBuilding foundation models is often highly resource-intensive, with the most expensive models costing hundreds of millions of dollars to pay for the underlying data and compute required. In contrast, adapting an existing foundation model for a specific task or using it directly is far less costly.\\nEarly examples of foundation models are language models (LMs) like OpenAI's GPT series and Google's BERT. Beyond text, foundation models have been developed across a range of modalities—including DALL-E and Flamingo for images, MusicGen for music, and RT-2 for robotic control. Foundation models are also being developed for fields like astronomy, radiology, genomics, music, coding, times-series forecasting, mathematics, and chemistry.\\n\\n\", 'source': 'https://en.wikipedia.org/wiki/Foundation_model'}, page_content='In the United Kingdom, the Competition and Markets Authority\\'s AI Foundation Models: Initial Report  defines foundations model as \"a type of AI technology that are trained on vast amounts of data that can be adapted to a wide range of tasks and operations.\"\\nThe United States\\'s definitions only ones to make reference to the size of a foundation model, and differ on magnitude. Beyer and Eshoo\\'s definition also specifies that foundation models must achieve a level of performance as to be a potential danger. In contrast, the E.U. definition requires the model to be designed for generality of output. All definitions agree that foundation models must be trained on a broad range of data with potential applications in many domains.'),\n",
       " Document(metadata={'title': 'Foundation model', 'summary': \"A foundation model, also known as large AI model, is a machine learning or deep learning model that is trained on vast datasets so it can be applied across a wide range of use cases. Generative AI applications like Large Language Models are often examples of foundation models.\\nBuilding foundation models is often highly resource-intensive, with the most expensive models costing hundreds of millions of dollars to pay for the underlying data and compute required. In contrast, adapting an existing foundation model for a specific task or using it directly is far less costly.\\nEarly examples of foundation models are language models (LMs) like OpenAI's GPT series and Google's BERT. Beyond text, foundation models have been developed across a range of modalities—including DALL-E and Flamingo for images, MusicGen for music, and RT-2 for robotic control. Foundation models are also being developed for fields like astronomy, radiology, genomics, music, coding, times-series forecasting, mathematics, and chemistry.\\n\\n\", 'source': 'https://en.wikipedia.org/wiki/Foundation_model'}, page_content='== History ==\\nTechnologically, foundation models are built using establi'),\n",
       " Document(metadata={'title': 'Model collapse', 'summary': 'Model collapse is a phenomenon where machine learning models gradually degrade due to errors coming from uncurated training on the outputs of another model, including prior versions of itself. Such outputs are known as synthetic data.\\nShumailov et al. coined the term and described two specific stages to the degradation: early model collapse and late model collapse. In early model collapse, the model begins losing information about the tails of the distribution – mostly affecting minority data. Later work highlighted that early model collapse is hard to notice, since overall performance may appear to improve, while the model loses performance on minority data. In late model collapse, the model loses a significant proportion of its performance, confusing concepts and losing most of its variance.', 'source': 'https://en.wikipedia.org/wiki/Model_collapse'}, page_content='Model collapse is a phenomenon where machine learning models gradually degrade due to errors coming from uncurated training on the outputs of another model, including prior versions of itself. Such outputs are known as synthetic data.\\nShumailov et al. coined the term and described two specific stages to the degradation: early model collapse and late model collapse. In early model collapse, the model begins losing information about the tails of the distribution – mostly affecting minority data. Later work highlighted that early model collapse is hard to notice, since overall performance may appear to improve, while the model loses performance on minority data. In late model collapse, the model loses a significant proportion of its performance, confusing concepts and losing most of its variance.\\n\\n\\n== Mechanism ==\\nSynthetic data, although theoretically indistinguishable from real data, is almost always biased, inaccurate, not well representative of the real data, harmful, or presented out-of-context. Using such data as training data leads to issues with the quality and reliability of the trained model.\\nModel collapse occurs for three main reasons – functional approximation errors, sampling errors, and learning errors. Importantly, it happens in even the simplest of models, where not all of the error sources are present. In more complex models the errors often compound, leading to faster collapse.\\n\\n\\n== Disagreement over real-world impact =='),\n",
       " Document(metadata={'title': 'Model collapse', 'summary': 'Model collapse is a phenomenon where machine learning models gradually degrade due to errors coming from uncurated training on the outputs of another model, including prior versions of itself. Such outputs are known as synthetic data.\\nShumailov et al. coined the term and described two specific stages to the degradation: early model collapse and late model collapse. In early model collapse, the model begins losing information about the tails of the distribution – mostly affecting minority data. Later work highlighted that early model collapse is hard to notice, since overall performance may appear to improve, while the model loses performance on minority data. In late model collapse, the model loses a significant proportion of its performance, confusing concepts and losing most of its variance.', 'source': 'https://en.wikipedia.org/wiki/Model_collapse'}, page_content='== Disagreement over real-world impact ==\\n\\nSome researchers and commentators on model collapse warn that the phenomenon could fundamentally threaten future generative AI development: As AI-generated data is shared on the Internet, it will inevitably end up in future training datasets, which are often crawled from the Internet. If training on \"slop\" (large quantities of unlabeled synthetic data) inevitably leads to model collapse, this could therefore pose a difficult problem.\\nHowever, recently, other researchers have disagreed with this argument, showing that if synthetic data accumulates alongside human-generated data, model collapse is avoided. The researchers argue that data accumulating over time is a more realistic description of reality than deleting all existing data every year, and that the real-world impact of model collapse may not be as catastrophic as feared. \\nAn alternative branch of the literature investigates the use of machine learning detectors and watermarking to identify model generated data and filter it out.\\n\\n\\n== Mathematical models of the phenomenon =='),\n",
       " Document(metadata={'title': 'Model collapse', 'summary': 'Model collapse is a phenomenon where machine learning models gradually degrade due to errors coming from uncurated training on the outputs of another model, including prior versions of itself. Such outputs are known as synthetic data.\\nShumailov et al. coined the term and described two specific stages to the degradation: early model collapse and late model collapse. In early model collapse, the model begins losing information about the tails of the distribution – mostly affecting minority data. Later work highlighted that early model collapse is hard to notice, since overall performance may appear to improve, while the model loses performance on minority data. In late model collapse, the model loses a significant proportion of its performance, confusing concepts and losing most of its variance.', 'source': 'https://en.wikipedia.org/wiki/Model_collapse'}, page_content='=== 1D Gaussian model ===\\nIn 2024, a first attempt has been made at illustrating collapse for the simplest possible model - a single dimensional normal distribution fit using unbiased estimators of mean and variance, computed on samples from the previous generation. \\nTo make this more precise, we say that original data follows a normal distribution \\n  \\n    \\n      \\n        \\n          X\\n          \\n            0\\n          \\n        \\n        ∼\\n        \\n          \\n            N\\n          \\n        \\n        (\\n        μ\\n        ,\\n        \\n          σ\\n          \\n            2'),\n",
       " Document(metadata={'title': 'Model collapse', 'summary': 'Model collapse is a phenomenon where machine learning models gradually degrade due to errors coming from uncurated training on the outputs of another model, including prior versions of itself. Such outputs are known as synthetic data.\\nShumailov et al. coined the term and described two specific stages to the degradation: early model collapse and late model collapse. In early model collapse, the model begins losing information about the tails of the distribution – mostly affecting minority data. Later work highlighted that early model collapse is hard to notice, since overall performance may appear to improve, while the model loses performance on minority data. In late model collapse, the model loses a significant proportion of its performance, confusing concepts and losing most of its variance.', 'source': 'https://en.wikipedia.org/wiki/Model_collapse'}, page_content='σ\\n          \\n            2\\n          \\n        \\n        )\\n      \\n    \\n    {\\\\displaystyle X^{0}\\\\sim {\\\\mathcal {N}}(\\\\mu ,\\\\sigma ^{2})}\\n  \\n, and we possess \\n  \\n    \\n      \\n        \\n          M\\n          \\n            0\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle M_{0}}\\n  \\n samples \\n  \\n    \\n      \\n        \\n          X\\n          \\n            j'),\n",
       " Document(metadata={'title': 'Model collapse', 'summary': 'Model collapse is a phenomenon where machine learning models gradually degrade due to errors coming from uncurated training on the outputs of another model, including prior versions of itself. Such outputs are known as synthetic data.\\nShumailov et al. coined the term and described two specific stages to the degradation: early model collapse and late model collapse. In early model collapse, the model begins losing information about the tails of the distribution – mostly affecting minority data. Later work highlighted that early model collapse is hard to notice, since overall performance may appear to improve, while the model loses performance on minority data. In late model collapse, the model loses a significant proportion of its performance, confusing concepts and losing most of its variance.', 'source': 'https://en.wikipedia.org/wiki/Model_collapse'}, page_content='X\\n          \\n            j\\n          \\n          \\n            0\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle X_{j}^{0}}\\n  \\n for \\n  \\n    \\n      \\n        j\\n        =\\n        1\\n        ,\\n        …\\n        ,\\n        \\n          M\\n          \\n            0\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle j=1,\\\\dots ,M_{0}}\\n  \\n. Denoting a general sample'),\n",
       " Document(metadata={'title': 'Model collapse', 'summary': 'Model collapse is a phenomenon where machine learning models gradually degrade due to errors coming from uncurated training on the outputs of another model, including prior versions of itself. Such outputs are known as synthetic data.\\nShumailov et al. coined the term and described two specific stages to the degradation: early model collapse and late model collapse. In early model collapse, the model begins losing information about the tails of the distribution – mostly affecting minority data. Later work highlighted that early model collapse is hard to notice, since overall performance may appear to improve, while the model loses performance on minority data. In late model collapse, the model loses a significant proportion of its performance, confusing concepts and losing most of its variance.', 'source': 'https://en.wikipedia.org/wiki/Model_collapse'}, page_content='{\\\\displaystyle j=1,\\\\dots ,M_{0}}\\n  \\n. Denoting a general sample \\n  \\n    \\n      \\n        \\n          X\\n          \\n            j\\n          \\n          \\n            i\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle X_{j}^{i}}\\n  \\n as sample \\n  \\n    \\n      \\n        j\\n        =\\n        1\\n        ,\\n        …\\n        ,'),\n",
       " Document(metadata={'title': 'Mistral AI', 'summary': 'Mistral AI is a French company specializing in artificial intelligence (AI) products, headquartered in Paris. Founded in April 2023 by former employees of Meta Platforms and Google DeepMind, it has quickly risen to prominence in the AI sector. The company is named after the mistral, a strong, cold, northwesterly wind that blows in southern France.\\nMistral AI focuses on producing open weight large language models, positioning itself as an alternative to proprietary models.\\nIn October 2023, Mistral AI raised €385 million. By December 2023, it was valued at over $2 billion.\\nIn June 2024, Mistral AI announced a new funding round of €600 million ($645 million), significantly boosting its valuation to €5.8 billion ($6.2 billion). This round was led by the venture capital firm General Catalyst, with participation from existing investors.\\nMistral AI has published three open-source models available as weights. Additionally, three more models—Small, Medium, and Large—are available via API only.\\nBased on valuation, the company is in fourth place in the global AI race and in first place outside the San Francisco Bay Area, ahead of several of its peers, such as Cohere, Hugging Face, Inflection, Perplexity and Together. Mistral AI aims to \"democratize\" AI by focusing on open-source innovation.', 'source': 'https://en.wikipedia.org/wiki/Mistral_AI'}, page_content='Mistral AI is a French company specializing in artificial intelligence (AI) products, headquartered in Paris. Founded in April 2023 by former employees of Meta Platforms and Google DeepMind, it has quickly risen to prominence in the AI sector. The company is named after the mistral, a strong, cold, northwesterly wind that blows in southern France.\\nMistral AI focuses on producing open weight large language models, positioning itself as an alternative to proprietary models.\\nIn October 2023, Mistral AI raised €385 million. By December 2023, it was valued at over $2 billion.\\nIn June 2024, Mistral AI announced a new funding round of €600 million ($645 million), significantly boosting its valuation to €5.8 billion ($6.2 billion). This round was led by the venture capital firm General Catalyst, with participation from existing investors.\\nMistral AI has published three open-source models available as weights. Additionally, three more models—Small, Medium, and Large—are available via API only.\\nBased on valuation, the company is in fourth place in the global AI race and in first place outside the San Francisco Bay Area, ahead of several of its peers, such as Cohere, Hugging Face, Inflection, Perplexity and Together. Mistral AI aims to \"democratize\" AI by focusing on open-source innovation.'),\n",
       " Document(metadata={'title': 'Mistral AI', 'summary': 'Mistral AI is a French company specializing in artificial intelligence (AI) products, headquartered in Paris. Founded in April 2023 by former employees of Meta Platforms and Google DeepMind, it has quickly risen to prominence in the AI sector. The company is named after the mistral, a strong, cold, northwesterly wind that blows in southern France.\\nMistral AI focuses on producing open weight large language models, positioning itself as an alternative to proprietary models.\\nIn October 2023, Mistral AI raised €385 million. By December 2023, it was valued at over $2 billion.\\nIn June 2024, Mistral AI announced a new funding round of €600 million ($645 million), significantly boosting its valuation to €5.8 billion ($6.2 billion). This round was led by the venture capital firm General Catalyst, with participation from existing investors.\\nMistral AI has published three open-source models available as weights. Additionally, three more models—Small, Medium, and Large—are available via API only.\\nBased on valuation, the company is in fourth place in the global AI race and in first place outside the San Francisco Bay Area, ahead of several of its peers, such as Cohere, Hugging Face, Inflection, Perplexity and Together. Mistral AI aims to \"democratize\" AI by focusing on open-source innovation.', 'source': 'https://en.wikipedia.org/wiki/Mistral_AI'}, page_content=\"== History ==\\nMistral AI was founded in April 2023 by three French AI researchers: Arthur Mensch, Guillaume Lample and Timothée Lacroix. Prior to founding Mistral AI, Mensch worked at Google DeepMind which is Google's artificial intelligence laboratory, while Lample and Lacroix worked at Meta Platforms. The three co-founders met while students at École polytechnique.\\nIn June 2023, the start-up carried out a first fundraising of €105 million ($117 million) with investors including the American fund Lightspeed Venture Partners, Eric Schmidt, Xavier Niel and JCDecaux. The valuation is then estimated by the Financial Times at €240 million ($267 million).\\nOn 27 September 2023, the company made its language processing model “Mistral 7B” available under the free Apache 2.0 license. This model has 7 billion parameters, a small size compared to its competitors.\\nOn 10 December 2023, Mistral AI announced that it had raised €385 million ($428 million) as part of its second fundraising. This round of financing notably involves the Californian fund Andreessen Horowitz, BNP Paribas and the software publisher Salesforce.\"),\n",
       " Document(metadata={'title': 'Mistral AI', 'summary': 'Mistral AI is a French company specializing in artificial intelligence (AI) products, headquartered in Paris. Founded in April 2023 by former employees of Meta Platforms and Google DeepMind, it has quickly risen to prominence in the AI sector. The company is named after the mistral, a strong, cold, northwesterly wind that blows in southern France.\\nMistral AI focuses on producing open weight large language models, positioning itself as an alternative to proprietary models.\\nIn October 2023, Mistral AI raised €385 million. By December 2023, it was valued at over $2 billion.\\nIn June 2024, Mistral AI announced a new funding round of €600 million ($645 million), significantly boosting its valuation to €5.8 billion ($6.2 billion). This round was led by the venture capital firm General Catalyst, with participation from existing investors.\\nMistral AI has published three open-source models available as weights. Additionally, three more models—Small, Medium, and Large—are available via API only.\\nBased on valuation, the company is in fourth place in the global AI race and in first place outside the San Francisco Bay Area, ahead of several of its peers, such as Cohere, Hugging Face, Inflection, Perplexity and Together. Mistral AI aims to \"democratize\" AI by focusing on open-source innovation.', 'source': 'https://en.wikipedia.org/wiki/Mistral_AI'}, page_content='On 11 December 2023, the company released the Mixtral 8x7B model with 46.7 billion parameters but using only 12.9 billion per token thanks to the mixture of experts architecture. The model masters 5 languages (French, Spanish, Italian, English and German) and outperforms, according to its developers\\' tests, the \"LLama 2 70B\" model from Meta. A version trained to follow instructions and called “Mixtral 8x7B Instruct” is also offered.\\nOn 26 February 2024, Microsoft announced a new partnership with the company to expand its presence in the rapidly evolving artificial intelligence industry. Under the agreement, Mistral\\'s rich language models will be available on Microsoft\\'s Azure cloud, while the multilingual conversational assistant \"Le Chat\" will be launched in the style of ChatGPT.\\nOn 10 April 2024, the company released the mixture of expert models, Mixtral 8x22B, offering high performance on various benchmarks compared to other open models.\\nOn 16 April 2024, reporting revealed that Mistral was in talks to raise €500 million, a deal that would more than double its current valuation to at least €5 billion.'),\n",
       " Document(metadata={'title': 'Mistral AI', 'summary': 'Mistral AI is a French company specializing in artificial intelligence (AI) products, headquartered in Paris. Founded in April 2023 by former employees of Meta Platforms and Google DeepMind, it has quickly risen to prominence in the AI sector. The company is named after the mistral, a strong, cold, northwesterly wind that blows in southern France.\\nMistral AI focuses on producing open weight large language models, positioning itself as an alternative to proprietary models.\\nIn October 2023, Mistral AI raised €385 million. By December 2023, it was valued at over $2 billion.\\nIn June 2024, Mistral AI announced a new funding round of €600 million ($645 million), significantly boosting its valuation to €5.8 billion ($6.2 billion). This round was led by the venture capital firm General Catalyst, with participation from existing investors.\\nMistral AI has published three open-source models available as weights. Additionally, three more models—Small, Medium, and Large—are available via API only.\\nBased on valuation, the company is in fourth place in the global AI race and in first place outside the San Francisco Bay Area, ahead of several of its peers, such as Cohere, Hugging Face, Inflection, Perplexity and Together. Mistral AI aims to \"democratize\" AI by focusing on open-source innovation.', 'source': 'https://en.wikipedia.org/wiki/Mistral_AI'}, page_content='On 16 April 2024, reporting revealed that Mistral was in talks to raise €500 million, a deal that would more than double its current valuation to at least €5 billion.\\nOn November 19, 2024, the company announced significant updates for Le Chat. It added the ability to create images, in partnership with Black Forest Labs, utilizing the Flux Pro models. Additionally, it introduced the capability to search for information on the internet to provide reliable and up-to-date information. Furthermore, it launched the Canvas system, a collaborative interface where the AI generates code and the user can modify it. The com'),\n",
       " Document(metadata={'title': 'Gemini (language model)', 'summary': \"Gemini is a family of multimodal large language models developed by Google DeepMind, serving as the successor to LaMDA and PaLM 2. Comprising Gemini Ultra, Gemini Pro, Gemini Flash, and Gemini Nano, it was announced on December 6, 2023, positioned as a competitor to OpenAI's GPT-4. It powers the chatbot of the same name.\", 'source': 'https://en.wikipedia.org/wiki/Gemini_(language_model)'}, page_content=\"Gemini is a family of multimodal large language models developed by Google DeepMind, serving as the successor to LaMDA and PaLM 2. Comprising Gemini Ultra, Gemini Pro, Gemini Flash, and Gemini Nano, it was announced on December 6, 2023, positioned as a competitor to OpenAI's GPT-4. It powers the chatbot of the same name.\\n\\n\\n== History ==\\n\\n\\n=== Development ===\"),\n",
       " Document(metadata={'title': 'Gemini (language model)', 'summary': \"Gemini is a family of multimodal large language models developed by Google DeepMind, serving as the successor to LaMDA and PaLM 2. Comprising Gemini Ultra, Gemini Pro, Gemini Flash, and Gemini Nano, it was announced on December 6, 2023, positioned as a competitor to OpenAI's GPT-4. It powers the chatbot of the same name.\", 'source': 'https://en.wikipedia.org/wiki/Gemini_(language_model)'}, page_content=\"Google announced Gemini, a large language model (LLM) developed by subsidiary Google DeepMind, during the Google I/O keynote on May 10, 2023. It was positioned as a more powerful successor to PaLM 2, which was also unveiled at the event, with Google CEO Sundar Pichai stating that Gemini was still in its early developmental stages. Unlike other LLMs, Gemini was said to be unique in that it was not trained on a text corpus alone and was designed to be multimodal, meaning it could process multiple types of data simultaneously, including text, images, audio, video, and computer code. It had been developed as a collaboration between DeepMind and Google Brain, two branches of Google that had been merged as Google DeepMind the previous month. In an interview with Wired, DeepMind CEO Demis Hassabis touted Gemini's advanced capabilities, which he believed would allow the algorithm to trump OpenAI's ChatGPT, which runs on GPT-4 and whose growing popularity had been aggressively challenged by Google with LaMDA and Bard. Hassabis highlighted the strengths of DeepMind's AlphaGo program, which gained worldwide attention in 2016 when it defeated Go champion Lee Sedol, saying that Gemini would combine the power of AlphaGo and other Google–DeepMind LLMs.\"),\n",
       " Document(metadata={'title': 'Gemini (language model)', 'summary': \"Gemini is a family of multimodal large language models developed by Google DeepMind, serving as the successor to LaMDA and PaLM 2. Comprising Gemini Ultra, Gemini Pro, Gemini Flash, and Gemini Nano, it was announced on December 6, 2023, positioned as a competitor to OpenAI's GPT-4. It powers the chatbot of the same name.\", 'source': 'https://en.wikipedia.org/wiki/Gemini_(language_model)'}, page_content='In August 2023, The Information published a report outlining Google\\'s roadmap for Gemini, revealing that the company was targeting a launch date of late 2023. According to the report, Google hoped to surpass OpenAI and other competitors by combining conversational text capabilities present in most LLMs with artificial intelligence–powered image generation, allowing it to create contextual images and be adapted for a wider range of use cases. Like Bard, Google co-founder Sergey Brin was summoned out of retirement to assist in the development of Gemini, along with hundreds of other engineers from Google Brain and DeepMind; he was later credited as a \"core contributor\" to Gemini. Because Gemini was being trained on transcripts of YouTube videos, lawyers were brought in to filter out any potentially copyrighted materials.\\nWith news of Gemini\\'s impending launch, OpenAI hastened its work on integrating GPT-4 with multimodal features similar to those of Gemini. The Information reported in September that several companies had been granted early access to \"an early version\" of the LLM, which Google intended to make available to clients through Google Cloud\\'s Vertex AI service. The publication also stated that Google was arming Gemini to compete with both GPT-4 and Microsoft\\'s GitHub Copilot.'),\n",
       " Document(metadata={'title': 'Gemini (language model)', 'summary': \"Gemini is a family of multimodal large language models developed by Google DeepMind, serving as the successor to LaMDA and PaLM 2. Comprising Gemini Ultra, Gemini Pro, Gemini Flash, and Gemini Nano, it was announced on December 6, 2023, positioned as a competitor to OpenAI's GPT-4. It powers the chatbot of the same name.\", 'source': 'https://en.wikipedia.org/wiki/Gemini_(language_model)'}, page_content='=== Launch ===\\nOn December 6, 2023, Pichai and Hassabis announced \"Gemini 1.0\" at a virtual press conference. It comprised three models: Gemini Ultra, designed for \"highly complex tasks\"; Gemini Pro, designed for \"a wide range of tasks\"; and Gemini Nano, designed for \"on-device tasks\". At launch, Gemini Pro and Nano were integrated into Bard and the Pixel 8 Pro smartphone, respectively, while Gemini Ultra was set to power \"Bard Advanced\" and become available to software developers in early 2024. Other products that Google intended to incorporate Gemini into included Search, Ads, Chrome, Duet AI on Google Workspace, and AlphaCode 2. It was made available only in English. Touted as Google\\'s \"largest and most capable AI model\" and designed to emulate human behavior, the company stated that Gemini would not be made widely available until the following year due to the need for \"extensive safety testing\". Gemini was trained on and powered by Google\\'s Tensor Processing Units (TPUs), and the name is in reference to the DeepMind–Google Brain merger as well as NASA\\'s'),\n",
       " Document(metadata={'title': 'GPT-3', 'summary': 'Generative Pre-trained Transformer 3 (GPT-3) is a large language model released by OpenAI in 2020.\\nLike its predecessor, GPT-2, it is a decoder-only transformer model of deep neural network, which supersedes recurrence and convolution-based architectures with a technique known as \"attention\". This attention mechanism allows the model to focus selectively on segments of input text it predicts to be most relevant. GPT-3 has 175 billion parameters, each with 16-bit precision, requiring 350GB of storage since each parameter occupies 2 bytes. It has a context window size of 2048 tokens, and has demonstrated strong \"zero-shot\" and \"few-shot\" learning abilities on many tasks.\\nOn September 22, 2020, Microsoft announced that it had licensed GPT-3 exclusively. Others can still receive output from its public API, but only Microsoft has access to the underlying model.', 'source': 'https://en.wikipedia.org/wiki/GPT-3'}, page_content='Generative Pre-trained Transformer 3 (GPT-3) is a large language model released by OpenAI in 2020.\\nLike its predecessor, GPT-2, it is a decoder-only transformer model of deep neural network, which supersedes recurrence and convolution-based architectures with a technique known as \"attention\". This attention mechanism allows the model to focus selectively on segments of input text it predicts to be most relevant. GPT-3 has 175 billion parameters, each with 16-bit precision, requiring 350GB of storage since each parameter occupies 2 bytes. It has a context window size of 2048 tokens, and has demonstrated strong \"zero-shot\" and \"few-shot\" learning abilities on many tasks.\\nOn September 22, 2020, Microsoft announced that it had licensed GPT-3 exclusively. Others can still receive output from its public API, but only Microsoft has access to the underlying model.'),\n",
       " Document(metadata={'title': 'GPT-3', 'summary': 'Generative Pre-trained Transformer 3 (GPT-3) is a large language model released by OpenAI in 2020.\\nLike its predecessor, GPT-2, it is a decoder-only transformer model of deep neural network, which supersedes recurrence and convolution-based architectures with a technique known as \"attention\". This attention mechanism allows the model to focus selectively on segments of input text it predicts to be most relevant. GPT-3 has 175 billion parameters, each with 16-bit precision, requiring 350GB of storage since each parameter occupies 2 bytes. It has a context window size of 2048 tokens, and has demonstrated strong \"zero-shot\" and \"few-shot\" learning abilities on many tasks.\\nOn September 22, 2020, Microsoft announced that it had licensed GPT-3 exclusively. Others can still receive output from its public API, but only Microsoft has access to the underlying model.', 'source': 'https://en.wikipedia.org/wiki/GPT-3'}, page_content='== Background ==\\nAccording to The Economist, improved algorithms, more powerful computers, and a recent increase in the amount of digitized material have fueled a revolution in machine learning. New techniques in the 2010s resulted in \"rapid improvements in tasks\", including manipulating language.\\nSoftware models are trained to learn by using thousands or millions of examples in a \"structure ... loosely based on the neural architecture of the brain\". One architecture used in natural language processing (NLP) is a neural network based on a deep learning model that was introduced in 2017—the transformer architecture. There are a number of NLP systems capable of processing, mining, organizing, connecting and contrasting textual input, as well as correctly answering questions.'),\n",
       " Document(metadata={'title': 'GPT-3', 'summary': 'Generative Pre-trained Transformer 3 (GPT-3) is a large language model released by OpenAI in 2020.\\nLike its predecessor, GPT-2, it is a decoder-only transformer model of deep neural network, which supersedes recurrence and convolution-based architectures with a technique known as \"attention\". This attention mechanism allows the model to focus selectively on segments of input text it predicts to be most relevant. GPT-3 has 175 billion parameters, each with 16-bit precision, requiring 350GB of storage since each parameter occupies 2 bytes. It has a context window size of 2048 tokens, and has demonstrated strong \"zero-shot\" and \"few-shot\" learning abilities on many tasks.\\nOn September 22, 2020, Microsoft announced that it had licensed GPT-3 exclusively. Others can still receive output from its public API, but only Microsoft has access to the underlying model.', 'source': 'https://en.wikipedia.org/wiki/GPT-3'}, page_content='On June 11, 2018, OpenAI researchers and engineers published a paper introducing the first generative pre-trained transformer (GPT)—a type of generative large language model that is pre-trained with an enormous and diverse text corpus in datasets, followed by discriminative fine-tuning to focus on a specific task. GPT models are transformer-based deep-learning neural network architectures. Previously, the best-performing neural NLP models commonly employed supervised learning from large amounts of manually-labeled data, which made it prohibitively expensive and time-consuming to train extremely large language models. The first GPT model was known as \"GPT-1,\" and it was followed by \"GPT-2\" in February 2019. Created as a direct scale-up of its predecessor, GPT-2 had both its parameter count and dataset size increased by a factor of 10. It had 1.5 billion parameters, and was trained on a dataset of 8 million web pages. \\nIn February 2020, Microsoft introduced its Turing Natural Language Generation (T-NLG), which they claimed was \"largest language model ever published at 17 billion parameters.\" It performed better than any other language model at a variety of tasks, including summarizing texts and answering questions.'),\n",
       " Document(metadata={'title': 'GPT-3', 'summary': 'Generative Pre-trained Transformer 3 (GPT-3) is a large language model released by OpenAI in 2020.\\nLike its predecessor, GPT-2, it is a decoder-only transformer model of deep neural network, which supersedes recurrence and convolution-based architectures with a technique known as \"attention\". This attention mechanism allows the model to focus selectively on segments of input text it predicts to be most relevant. GPT-3 has 175 billion parameters, each with 16-bit precision, requiring 350GB of storage since each parameter occupies 2 bytes. It has a context window size of 2048 tokens, and has demonstrated strong \"zero-shot\" and \"few-shot\" learning abilities on many tasks.\\nOn September 22, 2020, Microsoft announced that it had licensed GPT-3 exclusively. Others can still receive output from its public API, but only Microsoft has access to the underlying model.', 'source': 'https://en.wikipedia.org/wiki/GPT-3'}, page_content='== Training and capabilities ==\\n\\nOn May 28, 2020, an arXiv preprint by a group of 31 engineers and researchers at OpenAI described the achievement and development of GPT-3, a third-generation \"state-of-the-art language model\". The team increased the capacity of GPT-3 by over two orders of magnitude from that of its predecessor, GPT-2, making GPT-3 the largest non-sparse language model to date.:\\u200a14\\u200a Because GPT-3 is structurally similar to its predecessors, its greater accuracy is attributed to its increased capacity and greater number of parameters. GPT-3\\'s capacity is ten times larger than that of Microsoft\\'s Turing NLG, the next largest NLP model known at the time.\\nLambdalabs estimated a hypothetical cost of around $4.6 million US dollars and 355 years to train GPT-3 on a single GPU in 2020, with lower actual training time by using more GPUs in parallel.\\nSixty percent of the weighted pre-training dataset for GPT-3 comes from a filtered version of Common Crawl consisting of 410 billion byte-pair-encoded tokens. Fuzzy deduplication used Apache Spark\\'s MinHashLSH.:\\u200a9\\u200a Other sources are 19 billi'),\n",
       " Document(metadata={'title': 'Stochastic parrot', 'summary': 'In machine learning, the term stochastic parrot is a metaphor to describe the theory that large language models, though able to generate plausible language, do not understand the meaning of the language they process. The term was coined by Emily M. Bender in the 2021 artificial intelligence research paper \"On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜\" by Bender, Timnit Gebru, Angelina McMillan-Major, and Margaret Mitchell.', 'source': 'https://en.wikipedia.org/wiki/Stochastic_parrot'}, page_content='In machine learning, the term stochastic parrot is a metaphor to describe the theory that large language models, though able to generate plausible language, do not understand the meaning of the language they process. The term was coined by Emily M. Bender in the 2021 artificial intelligence research paper \"On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜\" by Bender, Timnit Gebru, Angelina McMillan-Major, and Margaret Mitchell.\\n\\n\\n== Origin and definition ==\\nThe term was first used in the paper \"On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜\" by Bender, Timnit Gebru, Angelina McMillan-Major, and Margaret Mitchell (using the pseudonym \"Shmargaret Shmitchell\"). They argued that large language models (LLMs) present dangers such as environmental and financial costs, inscrutability leading to unknown dangerous biases, and potential for deception, and that they can\\'t understand the concepts underlying what they learn.\\n\\n\\n=== Etymology ===\\n\\nThe word \"stochastic\" – from the ancient Greek \"stokhastikos\" (\\'based on guesswork\\') – is a term from probability theory meaning \"randomly determined\". The word \"parrot\" refers to parrots\\' ability to mimic human speech, without understanding its meaning.'),\n",
       " Document(metadata={'title': 'Stochastic parrot', 'summary': 'In machine learning, the term stochastic parrot is a metaphor to describe the theory that large language models, though able to generate plausible language, do not understand the meaning of the language they process. The term was coined by Emily M. Bender in the 2021 artificial intelligence research paper \"On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜\" by Bender, Timnit Gebru, Angelina McMillan-Major, and Margaret Mitchell.', 'source': 'https://en.wikipedia.org/wiki/Stochastic_parrot'}, page_content='=== Purpose ===\\nIn their paper, Bender et al. argue that LLMs are probabilistically linking words and sentences together without considering meaning. Therefore, they are labeled to be mere \"stochastic parrots\". According to the machine learning professionals Lindholm, Wahlström, Lindsten, and Schön, the analogy highlights two vital limitations:\\n\\nLLMs are limited by the data they are trained by and are simply stochastically repeating contents of datasets.\\nBecause they are just making up outputs based on training data, LLMs do not understand if they are saying something incorrect or inappropriate.\\nLindholm et al. noted that, with poor quality datasets and other limitations, a learning machine might produce results that are \"dangerously wrong\".\\n\\n\\n=== Google involvement ===\\nGebru was asked by Google to retract the paper or remove the names of Google employees from it. According to Jeff Dean, the paper \"didn\\'t meet our bar for publication\". In response, Gebru listed conditions to be met, stating that otherwise they could \"work on a last date\". Dean wrote that one of these conditions was for Google to disclose the reviewers of the paper and their specific feedback, which Google declined. Shortly after, she received an email saying that Google was \"accepting her resignation\". Her firing sparked a protest by Google employees, who believed the intent was to censor Gebru\\'s criticism.'),\n",
       " Document(metadata={'title': 'Stochastic parrot', 'summary': 'In machine learning, the term stochastic parrot is a metaphor to describe the theory that large language models, though able to generate plausible language, do not understand the meaning of the language they process. The term was coined by Emily M. Bender in the 2021 artificial intelligence research paper \"On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜\" by Bender, Timnit Gebru, Angelina McMillan-Major, and Margaret Mitchell.', 'source': 'https://en.wikipedia.org/wiki/Stochastic_parrot'}, page_content='== Subsequent usage ==\\nIn July of 2021, the Alan Turing Institute hosted a keynote and panel discussion on the paper. As of September 2024, the paper has been cited in 4,789 publications. The term has been used in publications in the fields of law, grammar, narrative, and humanities. The authors continue to maintain their concerns about the dangers of chatbots based on large language models, such as GPT-4.\\nStochastic parrot is now a neologism used by AI skeptics to refer to machines\\' lack of understanding of the meaning of their outputs and is sometimes interpreted as a \"slur against AI\". Its use expanded further when Sam Altman, CEO of Open AI, used the term ironically when he tweeted, \"i am a stochastic parrot and so r u.\" The term was then designated to be the 2023 AI-related Word of the Year for the American Dialect Society, even over the words \"ChatGPT\" and \"LLM\".\\nThe phrase is often referenced by some researchers to describe LLMs as pattern matchers that can generate plausible human-like text through their vast amount of training data, merely parroting in a stochastic fashion. However, other researchers argue that LLMs are, in fact, able to understand language.'),\n",
       " Document(metadata={'title': 'Stochastic parrot', 'summary': 'In machine learning, the term stochastic parrot is a metaphor to describe the theory that large language models, though able to generate plausible language, do not understand the meaning of the language they process. The term was coined by Emily M. Bender in the 2021 artificial intelligence research paper \"On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜\" by Bender, Timnit Gebru, Angelina McMillan-Major, and Margaret Mitchell.', 'source': 'https://en.wikipedia.org/wiki/Stochastic_parrot'}, page_content='== Debate ==\\nSome LLMs, such as ChatGPT, have become capable of interacting with users in convincingly human-like conversations. The development of these new syste'),\n",
       " Document(metadata={'title': 'Prompt engineering', 'summary': 'Prompt engineering is the process of structuring an instruction that can be interpreted and understood by a generative artificial intelligence (AI) model. \\nA prompt is natural language text describing the task that an AI should perform. A prompt for a text-to-text language model can be a query such as \"what is Fermat\\'s little theorem?\", a command such as \"write a poem in the style of Edgar Allan Poe about leaves falling\", or a longer statement including context, instructions, and conversation history.\\nPrompt engineering may involve phrasing a query, specifying a style, choice of words and grammar, providing relevant context or assigning a role to the AI such as \"act as a native French speaker\".\\nWhen communicating with a text-to-image or a text-to-audio model, a typical prompt is a description of a desired output such as \"a high-quality photo of an astronaut riding a horse\" or \"Lo-fi slow BPM electro chill with organic samples\". Prompting a text-to-image model may involve adding, removing, emphasizing, and re-ordering words to achieve a desired subject, style, layout, lighting, and aesthetic.', 'source': 'https://en.wikipedia.org/wiki/Prompt_engineering'}, page_content='Prompt engineering is the process of structuring an instruction that can be interpreted and understood by a generative artificial intelligence (AI) model. \\nA prompt is natural language text describing the task that an AI should perform. A prompt for a text-to-text language model can be a query such as \"what is Fermat\\'s little theorem?\", a command such as \"write a poem in the style of Edgar Allan Poe about leaves falling\", or a longer statement including context, instructions, and conversation history.\\nPrompt engineering may involve phrasing a query, specifying a style, choice of words and grammar, providing relevant context or assigning a role to the AI such as \"act as a native French speaker\".\\nWhen communicating with a text-to-image or a text-to-audio model, a typical prompt is a description of a desired output such as \"a high-quality photo of an astronaut riding a horse\" or \"Lo-fi slow BPM electro chill with organic samples\". Prompting a text-to-image model may involve adding, removing, emphasizing, and re-ordering words to achieve a desired subject, style, layout, lighting, and aesthetic.'),\n",
       " Document(metadata={'title': 'Prompt engineering', 'summary': 'Prompt engineering is the process of structuring an instruction that can be interpreted and understood by a generative artificial intelligence (AI) model. \\nA prompt is natural language text describing the task that an AI should perform. A prompt for a text-to-text language model can be a query such as \"what is Fermat\\'s little theorem?\", a command such as \"write a poem in the style of Edgar Allan Poe about leaves falling\", or a longer statement including context, instructions, and conversation history.\\nPrompt engineering may involve phrasing a query, specifying a style, choice of words and grammar, providing relevant context or assigning a role to the AI such as \"act as a native French speaker\".\\nWhen communicating with a text-to-image or a text-to-audio model, a typical prompt is a description of a desired output such as \"a high-quality photo of an astronaut riding a horse\" or \"Lo-fi slow BPM electro chill with organic samples\". Prompting a text-to-image model may involve adding, removing, emphasizing, and re-ordering words to achieve a desired subject, style, layout, lighting, and aesthetic.', 'source': 'https://en.wikipedia.org/wiki/Prompt_engineering'}, page_content='== History ==\\nIn 2018, researchers first proposed that all previously separate tasks in NLP could be cast as a question answering problem over a context. In addition, they trained a first single, joint, multi-task model that would answer any task-related question like \"What is the sentiment\" or \"Translate this sentence to German\" or \"Who is the president?\"\\nIn 2021, researchers fine-tuned one generatively pretrained model (T0) on performing 12 NLP tasks (using 62 datasets, as each task can have multiple datasets). The model showed good performance on new tasks, surpassing models trained directly on just performing one task (without pretraining). To solve a task, T0 is given the task in a structured prompt, for example If {{premise}} is true, is it also true that {{hypothesis}}? ||| {{entailed}}. is the prompt used for making T0 solve entailment.\\nA repository for prompts reported that over 2,000 public prompts for around 170 datasets were available in February 2022.\\nIn 2022 the chain-of-thought prompting technique was proposed by Google researchers.\\nIn 2023 several text-to-text and text-to-image prompt databases were publicly available.\\n\\n\\n== Text-to-text =='),\n",
       " Document(metadata={'title': 'Prompt engineering', 'summary': 'Prompt engineering is the process of structuring an instruction that can be interpreted and understood by a generative artificial intelligence (AI) model. \\nA prompt is natural language text describing the task that an AI should perform. A prompt for a text-to-text language model can be a query such as \"what is Fermat\\'s little theorem?\", a command such as \"write a poem in the style of Edgar Allan Poe about leaves falling\", or a longer statement including context, instructions, and conversation history.\\nPrompt engineering may involve phrasing a query, specifying a style, choice of words and grammar, providing relevant context or assigning a role to the AI such as \"act as a native French speaker\".\\nWhen communicating with a text-to-image or a text-to-audio model, a typical prompt is a description of a desired output such as \"a high-quality photo of an astronaut riding a horse\" or \"Lo-fi slow BPM electro chill with organic samples\". Prompting a text-to-image model may involve adding, removing, emphasizing, and re-ordering words to achieve a desired subject, style, layout, lighting, and aesthetic.', 'source': 'https://en.wikipedia.org/wiki/Prompt_engineering'}, page_content='=== Chain-of-thought ===\\nAccording to Google, Chain-of-thought (CoT) prompting is claimed to be a technique that allows large language models (LLMs) to solve a problem as a series of intermediate steps before giving a final answer. In 2022, Google also claimed that chain-of-thought prompting improves reasoning ability by inducing the model to answer a multi-step problem with steps of reasoning that mimic a train of thought. Chain-of-thought techniques hypothetically allow large language models to overcome difficulties with some reasoning tasks that require logical thinking and multiple steps to solve, such as arithmetic or commonsense reasoning questions, according to announcements from Google and Amazon.\\nFor example, given the question \"Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?\", Google claims that a CoT prompt might induce the LLM to answer \"A: The cafeteria had 23 apples originally. They used 20 to make lunch. So they had 23 - 20 = 3. They bought 6 more apples, so they have 3 + 6 = 9. The answer is 9.\"'),\n",
       " Document(metadata={'title': 'Prompt engineering', 'summary': 'Prompt engineering is the process of structuring an instruction that can be interpreted and understood by a generative artificial intelligence (AI) model. \\nA prompt is natural language text describing the task that an AI should perform. A prompt for a text-to-text language model can be a query such as \"what is Fermat\\'s little theorem?\", a command such as \"write a poem in the style of Edgar Allan Poe about leaves falling\", or a longer statement including context, instructions, and conversation history.\\nPrompt engineering may involve phrasing a query, specifying a style, choice of words and grammar, providing relevant context or assigning a role to the AI such as \"act as a native French speaker\".\\nWhen communicating with a text-to-image or a text-to-audio model, a typical prompt is a description of a desired output such as \"a high-quality photo of an astronaut riding a horse\" or \"Lo-fi slow BPM electro chill with organic samples\". Prompting a text-to-image model may involve adding, removing, emphasizing, and re-ordering words to achieve a desired subject, style, layout, lighting, and aesthetic.', 'source': 'https://en.wikipedia.org/wiki/Prompt_engineering'}, page_content='As originally proposed by Google, each CoT prompt included a few Q&A examples. This made it a few-shot prompting technique. However, according to a researchers at Google and the University of Tokyo, simply appending the words \"Let\\'s think step-by-step\", has also proven effective, which makes CoT a zero-shot prompting technique. OpenAI claims that this prompt allows for better scaling as a user no longer needs to formulate many specific CoT Q&A examples.\\nWhen applied to PaLM, a 540B parameter language model, Google claims that CoT prompting significantly aided the model, allowing it to perform comparably with task-sp'),\n",
       " Document(metadata={'title': 'Dead Internet theory', 'summary': 'The dead Internet theory is an online conspiracy theory that asserts that, due to a coordinated and intentional effort, the Internet now consists mainly of bot activity and automatically generated content manipulated by algorithmic curation to control the population and minimize organic human activity. Proponents of the theory believe these social bots were created intentionally to help manipulate algorithms and boost search results in order to manipulate consumers. Some proponents of the theory accuse government agencies of using bots to manipulate public perception. The date given for this \"death\" is generally around 2016 or 2017. The dead Internet theory has gained traction because many of the observed phenomena are quantifiable, such as increased bot traffic, but the literature on the subject does not support the full theory.', 'source': 'https://en.wikipedia.org/wiki/Dead_Internet_theory'}, page_content='The dead Internet theory is an online conspiracy theory that asserts that, due to a coordinated and intentional effort, the Internet now consists mainly of bot activity and automatically generated content manipulated by algorithmic curation to control the population and minimize organic human activity. Proponents of the theory believe these social bots were created intentionally to help manipulate algorithms and boost search results in order to manipulate consumers. Some proponents of the theory accuse government agencies of using bots to manipulate public perception. The date given for this \"death\" is generally around 2016 or 2017. The dead Internet theory has gained traction because many of the observed phenomena are quantifiable, such as increased bot traffic, but the literature on the subject does not support the full theory. \\n\\n\\n== Origins and spread ==\\nThe dead Internet theory\\'s exact origin is difficult to pinpoint. In 2021, a post titled \"Dead Internet Theory: Most Of The Internet Is Fake\" was published onto the forum Agora Road\\'s Macintosh Cafe esoteric board by a user named \"IlluminatiPirate\", claiming to be building on previous posts from the same board and from Wizardchan, and marking the term\\'s spread beyond these initial imageboards. The conspiracy theory has entered public culture through widespread coverage and has been discussed on various high-profile YouTube channels. It gained more mainstream attention with an article in The Atlantic titled \"Maybe You Missed It, but the Internet \\'Died\\' Five Years Ago\". This article has been widely cited by other articles on the topic.'),\n",
       " Document(metadata={'title': 'Dead Internet theory', 'summary': 'The dead Internet theory is an online conspiracy theory that asserts that, due to a coordinated and intentional effort, the Internet now consists mainly of bot activity and automatically generated content manipulated by algorithmic curation to control the population and minimize organic human activity. Proponents of the theory believe these social bots were created intentionally to help manipulate algorithms and boost search results in order to manipulate consumers. Some proponents of the theory accuse government agencies of using bots to manipulate public perception. The date given for this \"death\" is generally around 2016 or 2017. The dead Internet theory has gained traction because many of the observed phenomena are quantifiable, such as increased bot traffic, but the literature on the subject does not support the full theory.', 'source': 'https://en.wikipedia.org/wiki/Dead_Internet_theory'}, page_content='== Claims ==\\nThe dead Internet theory has two main components: that organic human activity on the web has been displaced by bots and algorithmically curated search results, and that state actors are doing this in a coordinated effort to manipulate the human population. The first part of this theory, that bots create much of the content on the internet and perhaps contribute more than organic human content, has been a concern for a while, with the original post by \"IlluminatiPirate\" citing the article \"How Much of the Internet Is Fake? Turns Out, a Lot of It, Actually\" in New York magazine. The Dead Internet Theory goes on to include that Google, and other search engines, are censoring the Web by filtering content that is not desirable by limiting what is indexed and presented in search results. While Google may suggest that there are millions of search results for a query, the results available to a user do not reflect that.  This problem is exacerbated by the phenomenon known as link rot, which is caused when content at a website becomes unavailable, and all links to it on other sites break.  This has led to the theory that Google is a Potemkin village, and the searchable Web is much smaller than we are led to believe. The Dead Internet Theory suggests that this is part of the conspiracy to limit users to curated, and potentially artificial, content online.'),\n",
       " Document(metadata={'title': 'Dead Internet theory', 'summary': 'The dead Internet theory is an online conspiracy theory that asserts that, due to a coordinated and intentional effort, the Internet now consists mainly of bot activity and automatically generated content manipulated by algorithmic curation to control the population and minimize organic human activity. Proponents of the theory believe these social bots were created intentionally to help manipulate algorithms and boost search results in order to manipulate consumers. Some proponents of the theory accuse government agencies of using bots to manipulate public perception. The date given for this \"death\" is generally around 2016 or 2017. The dead Internet theory has gained traction because many of the observed phenomena are quantifiable, such as increased bot traffic, but the literature on the subject does not support the full theory.', 'source': 'https://en.wikipedia.org/wiki/Dead_Internet_theory'}, page_content='The second half of the dead Internet theory builds on this observable phenomenon by proposing that the U.S. government, corporations, or other actors are intentionally limiting users to curated, and potentially artificial AI-generated content, to manipulate the human population for a variety of reasons. In the original post, the idea that bots have displaced human content is described as the \"setup\", with the \"thesis\" of the theory itself focusing on the United States government being responsible for this, stating: \"The U.S. government is engaging in an artificial intelligence-powered gaslighting of the entire world population.\"'),\n",
       " Document(metadata={'title': 'Dead Internet theory', 'summary': 'The dead Internet theory is an online conspiracy theory that asserts that, due to a coordinated and intentional effort, the Internet now consists mainly of bot activity and automatically generated content manipulated by algorithmic curation to control the population and minimize organic human activity. Proponents of the theory believe these social bots were created intentionally to help manipulate algorithms and boost search results in order to manipulate consumers. Some proponents of the theory accuse government agencies of using bots to manipulate public perception. The date given for this \"death\" is generally around 2016 or 2017. The dead Internet theory has gained traction because many of the observed phenomena are quantifiable, such as increased bot traffic, but the literature on the subject does not support the full theory.', 'source': 'https://en.wikipedia.org/wiki/Dead_Internet_theory'}, page_content='== Expert view ==\\nCaroline Busta, founder of the media platform New Models, was quoted in an article in The Atlantic calling much of the dead Internet theory a \"paranoid fantasy\", even if there are legitimate criticisms involving bot traffic and the integrity of the internet, but she said she does agree with the \"overarching idea\". In an article in The New Atlan'),\n",
       " Document(metadata={'title': 'Word n-gram language model', 'summary': 'A word n-gram language model is a purely statistical model of language. It has been superseded by recurrent neural network–based models, which have been superseded by large language models. It is based on an assumption that the probability of the next word in a sequence depends only on a fixed size window of previous words. If only one previous word was considered, it was called a bigram model; if two words, a trigram model; if n − 1 words, an n-gram model. Special tokens were introduced to denote the start and end of a sentence \\n  \\n    \\n      \\n        ⟨\\n        s\\n        ⟩\\n      \\n    \\n    {\\\\displaystyle \\\\langle s\\\\rangle }\\n  \\n and \\n  \\n    \\n      \\n        ⟨\\n        \\n          /\\n        \\n        s\\n        ⟩\\n      \\n    \\n    {\\\\displaystyle \\\\langle /s\\\\rangle }\\n  \\n.\\nTo prevent a zero probability being assigned to unseen words, each word\\'s probability is slightly lower than its frequency count in a corpus. To calculate it, various methods were used, from simple \"add-one\" smoothing (assign a count of 1 to unseen n-grams, as an uninformative prior) to more sophisticated models, such as Good–Turing discounting or back-off models.', 'source': 'https://en.wikipedia.org/wiki/Word_n-gram_language_model'}, page_content='A word n-gram language model is a purely statistical model of language. It has been superseded by recurrent neural network–based models, which have been superseded by large language models. It is based on an assumption that the probability of the next word in a sequence depends only on a fixed size window of previous words. If only one previous word was considered, it was called a bigram model; if two words, a trigram model; if n − 1 words, an n-gram model. Special tokens were introduced to denote the start and end of a sentence \\n  \\n    \\n      \\n        ⟨\\n        s\\n        ⟩\\n      \\n    \\n    {\\\\displaystyle \\\\langle s\\\\rangle }\\n  \\n and \\n  \\n    \\n      \\n        ⟨\\n        \\n          /\\n        \\n        s\\n        ⟩\\n      \\n    \\n    {\\\\displaystyle \\\\langle /s\\\\rangle }'),\n",
       " Document(metadata={'title': 'Word n-gram language model', 'summary': 'A word n-gram language model is a purely statistical model of language. It has been superseded by recurrent neural network–based models, which have been superseded by large language models. It is based on an assumption that the probability of the next word in a sequence depends only on a fixed size window of previous words. If only one previous word was considered, it was called a bigram model; if two words, a trigram model; if n − 1 words, an n-gram model. Special tokens were introduced to denote the start and end of a sentence \\n  \\n    \\n      \\n        ⟨\\n        s\\n        ⟩\\n      \\n    \\n    {\\\\displaystyle \\\\langle s\\\\rangle }\\n  \\n and \\n  \\n    \\n      \\n        ⟨\\n        \\n          /\\n        \\n        s\\n        ⟩\\n      \\n    \\n    {\\\\displaystyle \\\\langle /s\\\\rangle }\\n  \\n.\\nTo prevent a zero probability being assigned to unseen words, each word\\'s probability is slightly lower than its frequency count in a corpus. To calculate it, various methods were used, from simple \"add-one\" smoothing (assign a count of 1 to unseen n-grams, as an uninformative prior) to more sophisticated models, such as Good–Turing discounting or back-off models.', 'source': 'https://en.wikipedia.org/wiki/Word_n-gram_language_model'}, page_content='s\\n        ⟩\\n      \\n    \\n    {\\\\displaystyle \\\\langle /s\\\\rangle }\\n  \\n.\\nTo prevent a zero probability being assigned to unseen words, each word\\'s probability is slightly lower than its frequency count in a corpus. To calculate it, various methods were used, from simple \"add-one\" smoothing (assign a count of 1 to unseen n-grams, as an uninformative prior) to more sophisticated models, such as Good–Turing discounting or back-off models.'),\n",
       " Document(metadata={'title': 'Word n-gram language model', 'summary': 'A word n-gram language model is a purely statistical model of language. It has been superseded by recurrent neural network–based models, which have been superseded by large language models. It is based on an assumption that the probability of the next word in a sequence depends only on a fixed size window of previous words. If only one previous word was considered, it was called a bigram model; if two words, a trigram model; if n − 1 words, an n-gram model. Special tokens were introduced to denote the start and end of a sentence \\n  \\n    \\n      \\n        ⟨\\n        s\\n        ⟩\\n      \\n    \\n    {\\\\displaystyle \\\\langle s\\\\rangle }\\n  \\n and \\n  \\n    \\n      \\n        ⟨\\n        \\n          /\\n        \\n        s\\n        ⟩\\n      \\n    \\n    {\\\\displaystyle \\\\langle /s\\\\rangle }\\n  \\n.\\nTo prevent a zero probability being assigned to unseen words, each word\\'s probability is slightly lower than its frequency count in a corpus. To calculate it, various methods were used, from simple \"add-one\" smoothing (assign a count of 1 to unseen n-grams, as an uninformative prior) to more sophisticated models, such as Good–Turing discounting or back-off models.', 'source': 'https://en.wikipedia.org/wiki/Word_n-gram_language_model'}, page_content=\"== Unigram model ==\\n\\nA special case, where n = 1, is called a unigram model. Probability of each word in a sequence is independent from probabilities of other word in the sequence. Each word's probability in the sequence is equal to the word's probability in an entire document.\"),\n",
       " Document(metadata={'title': 'Word n-gram language model', 'summary': 'A word n-gram language model is a purely statistical model of language. It has been superseded by recurrent neural network–based models, which have been superseded by large language models. It is based on an assumption that the probability of the next word in a sequence depends only on a fixed size window of previous words. If only one previous word was considered, it was called a bigram model; if two words, a trigram model; if n − 1 words, an n-gram model. Special tokens were introduced to denote the start and end of a sentence \\n  \\n    \\n      \\n        ⟨\\n        s\\n        ⟩\\n      \\n    \\n    {\\\\displaystyle \\\\langle s\\\\rangle }\\n  \\n and \\n  \\n    \\n      \\n        ⟨\\n        \\n          /\\n        \\n        s\\n        ⟩\\n      \\n    \\n    {\\\\displaystyle \\\\langle /s\\\\rangle }\\n  \\n.\\nTo prevent a zero probability being assigned to unseen words, each word\\'s probability is slightly lower than its frequency count in a corpus. To calculate it, various methods were used, from simple \"add-one\" smoothing (assign a count of 1 to unseen n-grams, as an uninformative prior) to more sophisticated models, such as Good–Turing discounting or back-off models.', 'source': 'https://en.wikipedia.org/wiki/Word_n-gram_language_model'}, page_content='P\\n          \\n            uni\\n          \\n        \\n        (\\n        \\n          t\\n          \\n            1\\n          \\n        \\n        \\n          t\\n          \\n            2\\n          \\n        \\n        \\n          t\\n          \\n            3\\n          \\n        \\n        )\\n        ='),\n",
       " Document(metadata={'title': 'Word n-gram language model', 'summary': 'A word n-gram language model is a purely statistical model of language. It has been superseded by recurrent neural network–based models, which have been superseded by large language models. It is based on an assumption that the probability of the next word in a sequence depends only on a fixed size window of previous words. If only one previous word was considered, it was called a bigram model; if two words, a trigram model; if n − 1 words, an n-gram model. Special tokens were introduced to denote the start and end of a sentence \\n  \\n    \\n      \\n        ⟨\\n        s\\n        ⟩\\n      \\n    \\n    {\\\\displaystyle \\\\langle s\\\\rangle }\\n  \\n and \\n  \\n    \\n      \\n        ⟨\\n        \\n          /\\n        \\n        s\\n        ⟩\\n      \\n    \\n    {\\\\displaystyle \\\\langle /s\\\\rangle }\\n  \\n.\\nTo prevent a zero probability being assigned to unseen words, each word\\'s probability is slightly lower than its frequency count in a corpus. To calculate it, various methods were used, from simple \"add-one\" smoothing (assign a count of 1 to unseen n-grams, as an uninformative prior) to more sophisticated models, such as Good–Turing discounting or back-off models.', 'source': 'https://en.wikipedia.org/wiki/Word_n-gram_language_model'}, page_content=')\\n        =\\n        P\\n        (\\n        \\n          t\\n          \\n            1\\n          \\n        \\n        )\\n        P\\n        (\\n        \\n          t\\n          \\n            2\\n          \\n        \\n        )\\n        P\\n        (\\n        \\n          t\\n          \\n            3'),\n",
       " Document(metadata={'title': 'Word n-gram language model', 'summary': 'A word n-gram language model is a purely statistical model of language. It has been superseded by recurrent neural network–based models, which have been superseded by large language models. It is based on an assumption that the probability of the next word in a sequence depends only on a fixed size window of previous words. If only one previous word was considered, it was called a bigram model; if two words, a trigram model; if n − 1 words, an n-gram model. Special tokens were introduced to denote the start and end of a sentence \\n  \\n    \\n      \\n        ⟨\\n        s\\n        ⟩\\n      \\n    \\n    {\\\\displaystyle \\\\langle s\\\\rangle }\\n  \\n and \\n  \\n    \\n      \\n        ⟨\\n        \\n          /\\n        \\n        s\\n        ⟩\\n      \\n    \\n    {\\\\displaystyle \\\\langle /s\\\\rangle }\\n  \\n.\\nTo prevent a zero probability being assigned to unseen words, each word\\'s probability is slightly lower than its frequency count in a corpus. To calculate it, various methods were used, from simple \"add-one\" smoothing (assign a count of 1 to unseen n-grams, as an uninformative prior) to more sophisticated models, such as Good–Turing discounting or back-off models.', 'source': 'https://en.wikipedia.org/wiki/Word_n-gram_language_model'}, page_content='t\\n          \\n            3\\n          \\n        \\n        )\\n        .\\n      \\n    \\n    {\\\\displaystyle P_{\\\\text{uni}}(t_{1}t_{2}t_{3})=P(t_{1})P(t_{2})P(t_{3}).}'),\n",
       " Document(metadata={'title': 'Word n-gram language model', 'summary': 'A word n-gram language model is a purely statistical model of language. It has been superseded by recurrent neural network–based models, which have been superseded by large language models. It is based on an assumption that the probability of the next word in a sequence depends only on a fixed size window of previous words. If only one previous word was considered, it was called a bigram model; if two words, a trigram model; if n − 1 words, an n-gram model. Special tokens were introduced to denote the start and end of a sentence \\n  \\n    \\n      \\n        ⟨\\n        s\\n        ⟩\\n      \\n    \\n    {\\\\displaystyle \\\\langle s\\\\rangle }\\n  \\n and \\n  \\n    \\n      \\n        ⟨\\n        \\n          /\\n        \\n        s\\n        ⟩\\n      \\n    \\n    {\\\\displaystyle \\\\langle /s\\\\rangle }\\n  \\n.\\nTo prevent a zero probability being assigned to unseen words, each word\\'s probability is slightly lower than its frequency count in a corpus. To calculate it, various methods were used, from simple \"add-one\" smoothing (assign a count of 1 to unseen n-grams, as an uninformative prior) to more sophisticated models, such as Good–Turing discounting or back-off models.', 'source': 'https://en.wikipedia.org/wiki/Word_n-gram_language_model'}, page_content=\"The model consists of units, each treated as one-state finite automata.  Words with their probabilities in a document can be illustrated as follows. \\n\\nTotal mass of word probabilities distributed across the document's vocabulary, is 1. \\n\\n  \\n    \\n      \\n        \\n          ∑\\n          \\n            word in doc\\n          \\n        \\n        P\\n        (\\n        \\n          word\\n        \\n        )\\n        =\\n        1\\n      \\n    \\n    {\\\\displaystyle \\\\sum _{\\\\text{word in doc}}P({\\\\text{word}})=1}\\n  \\n\\nThe probability generated for a specific query is calculated as\"),\n",
       " Document(metadata={'title': 'Word n-gram language model', 'summary': 'A word n-gram language model is a purely statistical model of language. It has been superseded by recurrent neural network–based models, which have been superseded by large language models. It is based on an assumption that the probability of the next word in a sequence depends only on a fixed size window of previous words. If only one previous word was considered, it was called a bigram model; if two words, a trigram model; if n − 1 words, an n-gram model. Special tokens were introduced to denote the start and end of a sentence \\n  \\n    \\n      \\n        ⟨\\n        s\\n        ⟩\\n      \\n    \\n    {\\\\displaystyle \\\\langle s\\\\rangle }\\n  \\n and \\n  \\n    \\n      \\n        ⟨\\n        \\n          /\\n        \\n        s\\n        ⟩\\n      \\n    \\n    {\\\\displaystyle \\\\langle /s\\\\rangle }\\n  \\n.\\nTo prevent a zero probability being assigned to unseen words, each word\\'s probability is slightly lower than its frequency count in a corpus. To calculate it, various methods were used, from simple \"add-one\" smoothing (assign a count of 1 to unseen n-grams, as an uninformative prior) to more sophisticated models, such as Good–Turing discounting or back-off models.', 'source': 'https://en.wikipedia.org/wiki/Word_n-gram_language_model'}, page_content='The probability generated for a specific query is calculated as\\n\\n  \\n    \\n      \\n        P\\n        (\\n        \\n          query\\n        \\n        )\\n        =\\n        \\n          ∏\\n          \\n            word in query\\n          \\n        \\n        P\\n        (\\n        \\n          word\\n        \\n        )\\n      \\n    \\n    {\\\\displaystyle P({\\\\text{query}})=\\\\prod _{\\\\text{word in query}}P({\\\\text{word}})}'),\n",
       " Document(metadata={'title': 'Word n-gram language model', 'summary': 'A word n-gram language model is a purely statistical model of language. It has been superseded by recurrent neural network–based models, which have been superseded by large language models. It is based on an assumption that the probability of the next word in a sequence depends only on a fixed size window of previous words. If only one previous word was considered, it was called a bigram model; if two words, a trigram model; if n − 1 words, an n-gram model. Special tokens were introduced to denote the start and end of a sentence \\n  \\n    \\n      \\n        ⟨\\n        s\\n        ⟩\\n      \\n    \\n    {\\\\displaystyle \\\\langle s\\\\rangle }\\n  \\n and \\n  \\n    \\n      \\n        ⟨\\n        \\n          /\\n        \\n        s\\n        ⟩\\n      \\n    \\n    {\\\\displaystyle \\\\langle /s\\\\rangle }\\n  \\n.\\nTo prevent a zero probability being assigned to unseen words, each word\\'s probability is slightly lower than its frequency count in a corpus. To calculate it, various methods were used, from simple \"add-one\" smoothing (assign a count of 1 to unseen n-grams, as an uninformative prior) to more sophisticated models, such as Good–Turing discounting or back-off models.', 'source': 'https://en.wikipedia.org/wiki/Word_n-gram_language_model'}, page_content='Unigram models of different documents have different probabilities of words in it. The probability distributions from different documents are used to generate hit probabilities for each query. Documents can be ranked for a query according to the probabilities. Example of unigram models of two documents:\\n\\n\\n== Bigram model ==\\nIn a bigram word (n = 2) language model, the probability of the sentence I saw the red house is approximated as'),\n",
       " Document(metadata={'title': 'Word n-gram language model', 'summary': 'A word n-gram language model is a purely statistical model of language. It has been superseded by recurrent neural network–based models, which have been superseded by large language models. It is based on an assumption that the probability of the next word in a sequence depends only on a fixed size window of previous words. If only one previous word was considered, it was called a bigram model; if two words, a trigram model; if n − 1 words, an n-gram model. Special tokens were introduced to denote the start and end of a sentence \\n  \\n    \\n      \\n        ⟨\\n        s\\n        ⟩\\n      \\n    \\n    {\\\\displaystyle \\\\langle s\\\\rangle }\\n  \\n and \\n  \\n    \\n      \\n        ⟨\\n        \\n          /\\n        \\n        s\\n        ⟩\\n      \\n    \\n    {\\\\displaystyle \\\\langle /s\\\\rangle }\\n  \\n.\\nTo prevent a zero probability being assigned to unseen words, each word\\'s probability is slightly lower than its frequency count in a corpus. To calculate it, various methods were used, from simple \"add-one\" smoothing (assign a count of 1 to unseen n-grams, as an uninformative prior) to more sophisticated models, such as Good–Turing discounting or back-off models.', 'source': 'https://en.wikipedia.org/wiki/Word_n-gram_language_model'}, page_content='P\\n        (\\n        \\n          I, saw, the, red, house\\n        \\n        )\\n        ≈\\n        P\\n        (\\n        \\n          I\\n        \\n        ∣\\n        ⟨\\n        s\\n        ⟩\\n        )\\n        P\\n        (\\n        \\n          saw\\n        \\n        ∣\\n        \\n          I\\n        \\n        )\\n        P\\n        ('),\n",
       " Document(metadata={'title': 'Word n-gram language model', 'summary': 'A word n-gram language model is a purely statistical model of language. It has been superseded by recurrent neural network–based models, which have been superseded by large language models. It is based on an assumption that the probability of the next word in a sequence depends only on a fixed size window of previous words. If only one previous word was considered, it was called a bigram model; if two words, a trigram model; if n − 1 words, an n-gram model. Special tokens were introduced to denote the start and end of a sentence \\n  \\n    \\n      \\n        ⟨\\n        s\\n        ⟩\\n      \\n    \\n    {\\\\displaystyle \\\\langle s\\\\rangle }\\n  \\n and \\n  \\n    \\n      \\n        ⟨\\n        \\n          /\\n        \\n        s\\n        ⟩\\n      \\n    \\n    {\\\\displaystyle \\\\langle /s\\\\rangle }\\n  \\n.\\nTo prevent a zero probability being assigned to unseen words, each word\\'s probability is slightly lower than its frequency count in a corpus. To calculate it, various methods were used, from simple \"add-one\" smoothing (assign a count of 1 to unseen n-grams, as an uninformative prior) to more sophisticated models, such as Good–Turing discounting or back-off models.', 'source': 'https://en.wikipedia.org/wiki/Word_n-gram_language_model'}, page_content='I\\n        \\n        )\\n        P\\n        (\\n        \\n          the\\n        \\n        ∣\\n        \\n          saw\\n        \\n        )\\n        P\\n        (\\n        \\n          red\\n        \\n        ∣\\n        \\n          the\\n        \\n        )\\n        P\\n        ('),\n",
       " Document(metadata={'title': 'ChatGPT', 'summary': 'ChatGPT is a generative artificial intelligence (AI) chatbot developed by OpenAI and launched in 2022. It is based on the GPT-4o large language model (LLM). ChatGPT can generate human-like conversational responses, and enables users to refine and steer a conversation towards a desired length, format, style, level of detail, and language. It is credited with accelerating the AI boom, which has led to ongoing rapid investment in and public attention to the field of artificial intelligence. Some observers have raised concern about the potential of ChatGPT and similar programs to displace human intelligence, enable plagiarism, or fuel misinformation.\\nBy January 2023, ChatGPT had become what was then the fastest-growing consumer software application in history, gaining over 100 million users in two months and contributing to the growth of OpenAI\\'s current valuation of $86 billion. ChatGPT\\'s release spurred the release of competing products, including Gemini, Claude, Llama, Ernie, and Grok. Microsoft launched Copilot, initially based on OpenAI\\'s GPT-4. In May 2024, a partnership between Apple Inc. and OpenAI was announced, in which ChatGPT was integrated into the Apple Intelligence feature of Apple operating systems. As of July 2024, ChatGPT\\'s website is among the 10 most-visited websites globally.\\nChatGPT is built on OpenAI\\'s proprietary series of generative pre-trained transformer (GPT) models, and is fine-tuned for conversational applications using a combination of supervised learning and reinforcement learning from human feedback. Successive user prompts and replies are considered at each conversation stage as context. ChatGPT was released as a freely available research preview, but due to its popularity, OpenAI now operates the service on a freemium model. Users on its free tier can access GPT-4o. The ChatGPT subscriptions \"Plus\", \"Team\", and \"Enterprise\" provide additional features such as DALL-E 3 image generation and an increased usage limit.', 'source': 'https://en.wikipedia.org/wiki/ChatGPT'}, page_content=\"ChatGPT is a generative artificial intelligence (AI) chatbot developed by OpenAI and launched in 2022. It is based on the GPT-4o large language model (LLM). ChatGPT can generate human-like conversational responses, and enables users to refine and steer a conversation towards a desired length, format, style, level of detail, and language. It is credited with accelerating the AI boom, which has led to ongoing rapid investment in and public attention to the field of artificial intelligence. Some observers have raised concern about the potential of ChatGPT and similar programs to displace human intelligence, enable plagiarism, or fuel misinformation.\\nBy January 2023, ChatGPT had become what was then the fastest-growing consumer software application in history, gaining over 100 million users in two months and contributing to the growth of OpenAI's current valuation of $86 billion. ChatGPT's release spurred the release of competing products, including Gemini, Claude, Llama, Ernie, and Grok. Microsoft launched Copilot, initially based on OpenAI's GPT-4. In May 2024, a partnership between Apple Inc. and OpenAI was announced, in which ChatGPT was integrated into the Apple Intelligence feature of Apple operating systems. As of July 2024, ChatGPT's website is among the 10 most-visited websites globally.\"),\n",
       " Document(metadata={'title': 'ChatGPT', 'summary': 'ChatGPT is a generative artificial intelligence (AI) chatbot developed by OpenAI and launched in 2022. It is based on the GPT-4o large language model (LLM). ChatGPT can generate human-like conversational responses, and enables users to refine and steer a conversation towards a desired length, format, style, level of detail, and language. It is credited with accelerating the AI boom, which has led to ongoing rapid investment in and public attention to the field of artificial intelligence. Some observers have raised concern about the potential of ChatGPT and similar programs to displace human intelligence, enable plagiarism, or fuel misinformation.\\nBy January 2023, ChatGPT had become what was then the fastest-growing consumer software application in history, gaining over 100 million users in two months and contributing to the growth of OpenAI\\'s current valuation of $86 billion. ChatGPT\\'s release spurred the release of competing products, including Gemini, Claude, Llama, Ernie, and Grok. Microsoft launched Copilot, initially based on OpenAI\\'s GPT-4. In May 2024, a partnership between Apple Inc. and OpenAI was announced, in which ChatGPT was integrated into the Apple Intelligence feature of Apple operating systems. As of July 2024, ChatGPT\\'s website is among the 10 most-visited websites globally.\\nChatGPT is built on OpenAI\\'s proprietary series of generative pre-trained transformer (GPT) models, and is fine-tuned for conversational applications using a combination of supervised learning and reinforcement learning from human feedback. Successive user prompts and replies are considered at each conversation stage as context. ChatGPT was released as a freely available research preview, but due to its popularity, OpenAI now operates the service on a freemium model. Users on its free tier can access GPT-4o. The ChatGPT subscriptions \"Plus\", \"Team\", and \"Enterprise\" provide additional features such as DALL-E 3 image generation and an increased usage limit.', 'source': 'https://en.wikipedia.org/wiki/ChatGPT'}, page_content='ChatGPT is built on OpenAI\\'s proprietary series of generative pre-trained transformer (GPT) models, and is fine-tuned for conversational applications using a combination of supervised learning and reinforcement learning from human feedback. Successive user prompts and replies are considered at each conversation stage as context. ChatGPT was released as a freely available research preview, but due to its popularity, OpenAI now operates the service on a freemium model. Users on its free tier can access GPT-4o. The ChatGPT subscriptions \"Plus\", \"Team\", and \"Enterprise\" provide additional features such as DALL-E 3 image generation and an increased usage limit.'),\n",
       " Document(metadata={'title': 'ChatGPT', 'summary': 'ChatGPT is a generative artificial intelligence (AI) chatbot developed by OpenAI and launched in 2022. It is based on the GPT-4o large language model (LLM). ChatGPT can generate human-like conversational responses, and enables users to refine and steer a conversation towards a desired length, format, style, level of detail, and language. It is credited with accelerating the AI boom, which has led to ongoing rapid investment in and public attention to the field of artificial intelligence. Some observers have raised concern about the potential of ChatGPT and similar programs to displace human intelligence, enable plagiarism, or fuel misinformation.\\nBy January 2023, ChatGPT had become what was then the fastest-growing consumer software application in history, gaining over 100 million users in two months and contributing to the growth of OpenAI\\'s current valuation of $86 billion. ChatGPT\\'s release spurred the release of competing products, including Gemini, Claude, Llama, Ernie, and Grok. Microsoft launched Copilot, initially based on OpenAI\\'s GPT-4. In May 2024, a partnership between Apple Inc. and OpenAI was announced, in which ChatGPT was integrated into the Apple Intelligence feature of Apple operating systems. As of July 2024, ChatGPT\\'s website is among the 10 most-visited websites globally.\\nChatGPT is built on OpenAI\\'s proprietary series of generative pre-trained transformer (GPT) models, and is fine-tuned for conversational applications using a combination of supervised learning and reinforcement learning from human feedback. Successive user prompts and replies are considered at each conversation stage as context. ChatGPT was released as a freely available research preview, but due to its popularity, OpenAI now operates the service on a freemium model. Users on its free tier can access GPT-4o. The ChatGPT subscriptions \"Plus\", \"Team\", and \"Enterprise\" provide additional features such as DALL-E 3 image generation and an increased usage limit.', 'source': 'https://en.wikipedia.org/wiki/ChatGPT'}, page_content='== Training =='),\n",
       " Document(metadata={'title': 'ChatGPT', 'summary': 'ChatGPT is a generative artificial intelligence (AI) chatbot developed by OpenAI and launched in 2022. It is based on the GPT-4o large language model (LLM). ChatGPT can generate human-like conversational responses, and enables users to refine and steer a conversation towards a desired length, format, style, level of detail, and language. It is credited with accelerating the AI boom, which has led to ongoing rapid investment in and public attention to the field of artificial intelligence. Some observers have raised concern about the potential of ChatGPT and similar programs to displace human intelligence, enable plagiarism, or fuel misinformation.\\nBy January 2023, ChatGPT had become what was then the fastest-growing consumer software application in history, gaining over 100 million users in two months and contributing to the growth of OpenAI\\'s current valuation of $86 billion. ChatGPT\\'s release spurred the release of competing products, including Gemini, Claude, Llama, Ernie, and Grok. Microsoft launched Copilot, initially based on OpenAI\\'s GPT-4. In May 2024, a partnership between Apple Inc. and OpenAI was announced, in which ChatGPT was integrated into the Apple Intelligence feature of Apple operating systems. As of July 2024, ChatGPT\\'s website is among the 10 most-visited websites globally.\\nChatGPT is built on OpenAI\\'s proprietary series of generative pre-trained transformer (GPT) models, and is fine-tuned for conversational applications using a combination of supervised learning and reinforcement learning from human feedback. Successive user prompts and replies are considered at each conversation stage as context. ChatGPT was released as a freely available research preview, but due to its popularity, OpenAI now operates the service on a freemium model. Users on its free tier can access GPT-4o. The ChatGPT subscriptions \"Plus\", \"Team\", and \"Enterprise\" provide additional features such as DALL-E 3 image generation and an increased usage limit.', 'source': 'https://en.wikipedia.org/wiki/ChatGPT'}, page_content='ChatGPT is based on particular GPT foundation models, namely GPT-4, GPT-4o and GPT-4o mini, that were fine-tuned to target conversational usage. The fine-tuning process leveraged supervised learning and reinforcement learning from human feedback (RLHF). Both approaches employed human trainers to improve model performance. In the case of supervised learning, the trainers played both sides: the user and the AI assistant. In the reinforcement learning stage, human trainers first ranked responses that the model had created in a previous conversation. These rankings were used to create \"reward models\" that were used to fine-tune the model further by using several iterations of proximal policy optimization.\\nTime magazine revealed that to build a safety system against harmful content (e.g., sexual abuse, violence, racism, sexism), OpenAI used outsourced Kenyan workers earning less than $2 per hour to label harmful content. These labels were used to train a model to detect such content in the future. The outsourced laborers were exposed to \"toxic\" and traumatic content; one worker described the assignment as \"torture\". OpenAI\\'s outsourcing partner was Sama, a training-data company based in San Francisco, California.'),\n",
       " Document(metadata={'title': 'ChatGPT', 'summary': 'ChatGPT is a generative artificial intelligence (AI) chatbot developed by OpenAI and launched in 2022. It is based on the GPT-4o large language model (LLM). ChatGPT can generate human-like conversational responses, and enables users to refine and steer a conversation towards a desired length, format, style, level of detail, and language. It is credited with accelerating the AI boom, which has led to ongoing rapid investment in and public attention to the field of artificial intelligence. Some observers have raised concern about the potential of ChatGPT and similar programs to displace human intelligence, enable plagiarism, or fuel misinformation.\\nBy January 2023, ChatGPT had become what was then the fastest-growing consumer software application in history, gaining over 100 million users in two months and contributing to the growth of OpenAI\\'s current valuation of $86 billion. ChatGPT\\'s release spurred the release of competing products, including Gemini, Claude, Llama, Ernie, and Grok. Microsoft launched Copilot, initially based on OpenAI\\'s GPT-4. In May 2024, a partnership between Apple Inc. and OpenAI was announced, in which ChatGPT was integrated into the Apple Intelligence feature of Apple operating systems. As of July 2024, ChatGPT\\'s website is among the 10 most-visited websites globally.\\nChatGPT is built on OpenAI\\'s proprietary series of generative pre-trained transformer (GPT) models, and is fine-tuned for conversational applications using a combination of supervised learning and reinforcement learning from human feedback. Successive user prompts and replies are considered at each conversation stage as context. ChatGPT was released as a freely available research preview, but due to its popularity, OpenAI now operates the service on a freemium model. Users on its free tier can access GPT-4o. The ChatGPT subscriptions \"Plus\", \"Team\", and \"Enterprise\" provide additional features such as DALL-E 3 image generation and an increased usage limit.', 'source': 'https://en.wikipedia.org/wiki/ChatGPT'}, page_content='ChatGPT initially used a Microsoft Azure supercomputing infrastructure, powered by Nvidia GPUs, that Microsoft built specifically for OpenAI and that reportedly cost \"hundreds of millions of dollars\". Following ChatGPT\\'s success, Microsoft dramatically upgraded the OpenAI infrastructure in 2023. Scientists at the University of California, Riverside, estimate that a series of prompts to ChatGPT needs approximately 500 milliliters (18 imp fl oz; 17 U.S. fl oz) of water for Microsoft servers cooling. TrendForce market intelligence estimated that 30,000 Nvidia GPUs (each costing approximately $10,000–15,000) were used to power ChatGPT in 2023.\\nOpenAI collects data from ChatGPT users to train and fine-tune the service further. Users can upvote or downvote responses they'),\n",
       " Document(metadata={'title': 'Transformer (deep learning architecture)', 'summary': 'A transformer is a deep learning architecture developed by researchers at Google and based on the multi-head attention mechanism, proposed in the 2017 paper \"Attention Is All You Need\". Text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished.\\nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLM) on large (language) datasets, such as the Wikipedia corpus and Common Crawl.\\n\\nTransformers were first developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language processing, computer vision (vision transformers), reinforcement learning, audio, multimodal learning, robotics, and even playing chess. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (bidirectional encoder representations from transformers).', 'source': 'https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)'}, page_content='A transformer is a deep learning architecture developed by researchers at Google and based on the multi-head attention mechanism, proposed in the 2017 paper \"Attention Is All You Need\". Text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished.\\nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLM) on large (language) datasets, such as the Wikipedia corpus and Common Crawl.\\n\\nTransformers were first developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language processing, computer vision (vision transformers), reinforcement learning, audio, multimodal learning, robotics, and even playing chess. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (bidirectional encoder representations from transformers).\\n\\n\\n== History =='),\n",
       " Document(metadata={'title': 'Transformer (deep learning architecture)', 'summary': 'A transformer is a deep learning architecture developed by researchers at Google and based on the multi-head attention mechanism, proposed in the 2017 paper \"Attention Is All You Need\". Text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished.\\nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLM) on large (language) datasets, such as the Wikipedia corpus and Common Crawl.\\n\\nTransformers were first developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language processing, computer vision (vision transformers), reinforcement learning, audio, multimodal learning, robotics, and even playing chess. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (bidirectional encoder representations from transformers).', 'source': 'https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)'}, page_content=\"=== Predecessors ===\\nFor many years, sequence modelling and generation was done by using plain recurrent neural networks (RNNs). A well-cited early example was the Elman network (1990). In theory, the information from one token can propagate arbitrarily far down the sequence, but in practice the vanishing-gradient problem leaves the model's state at the end of a long sentence without precise, extractable information about preceding tokens.\\nA key breakthrough was LSTM (1995), a RNN which used various innovations to overcome the vanishing gradient problem, allowing efficient learning of long-sequence modelling. One key innovation was the use of an attention mechanism which used neurons that multiply the outputs of other neurons, so-called multiplicative units. Neural networks using multiplicative units were later called sigma-pi networks or higher-order networks. LSTM became the standard architecture for long sequence modelling until the 2017 publication of Transformers.\\nHowever, LSTM still used sequential processing, like most other RNNs. Specifically, RNNs operate one token at a time from first to last; they cannot operate in parallel over all tokens in a sequence.\"),\n",
       " Document(metadata={'title': 'Transformer (deep learning architecture)', 'summary': 'A transformer is a deep learning architecture developed by researchers at Google and based on the multi-head attention mechanism, proposed in the 2017 paper \"Attention Is All You Need\". Text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished.\\nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLM) on large (language) datasets, such as the Wikipedia corpus and Common Crawl.\\n\\nTransformers were first developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language processing, computer vision (vision transformers), reinforcement learning, audio, multimodal learning, robotics, and even playing chess. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (bidirectional encoder representations from transformers).', 'source': 'https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)'}, page_content='However, LSTM still used sequential processing, like most other RNNs. Specifically, RNNs operate one token at a time from first to last; they cannot operate in parallel over all tokens in a sequence. \\nModern Transformers overcome this problem, but unlike RNNs, they require computation time that is quadratic in the size of the context window.  The linearly scaling fast weight controller (1992) learns  to compute a  weight matrix for further processing depending on the input. One of its two networks has  \"fast weights\" or \"dynamic links\" (1981). A slow neural network learns by gradient descent to generate keys and values for computing the weight changes of the fast neural network which computes answers to queries. This was later shown to be equivalent to the unnormalized linear Transformer.'),\n",
       " Document(metadata={'title': 'Transformer (deep learning architecture)', 'summary': 'A transformer is a deep learning architecture developed by researchers at Google and based on the multi-head attention mechanism, proposed in the 2017 paper \"Attention Is All You Need\". Text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished.\\nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLM) on large (language) datasets, such as the Wikipedia corpus and Common Crawl.\\n\\nTransformers were first developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language processing, computer vision (vision transformers), reinforcement learning, audio, multimodal learning, robotics, and even playing chess. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (bidirectional encoder representations from transformers).', 'source': 'https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)'}, page_content='=== Attention with seq2seq ===\\n\\nThe idea of encoder-decoder sequence transduction had been developed in the early 2010s (see previous papers). The papers most commonly cited as the originators that produced seq2seq are two concurrently published papers from 2014.\\nA 380M-parameter model for machine translation uses two long short-term memories (LSTM). Its architecture consists of two parts. The encoder is an LSTM that takes in a sequence of tokens and turns it into a vector. The decoder is another LSTM that converts the vector into a sequence of tokens. Similarly, another 130M-parameter model used gated recurrent units (GRU) instead of LSTM. Later research showed that GRUs are neither better nor worse than LSTMs for seq2seq.\\nThese early seq'),\n",
       " Document(metadata={'title': 'Fine-tuning (deep learning)', 'summary': 'In deep learning, fine-tuning is an approach to transfer learning in which the parameters of a pre-trained neural network model are trained on new data. Fine-tuning can be done on the entire neural network, or on only a subset of its layers, in which case the layers that are not being fine-tuned are \"frozen\" (i.e., not changed during backpropagation). A model may also be augmented with \"adapters\" that consist of far fewer parameters than the original model, and fine-tuned in a parameter-efficient way by tuning the weights of the adapters and leaving the rest of the model\\'s weights frozen.\\nFor some architectures, such as convolutional neural networks, it is common to keep the earlier layers (those closest to the input layer) frozen, as they capture lower-level features, while later layers often discern high-level features that can be more related to the task that the model is trained on.\\nModels that are pre-trained on large, general corpora are usually fine-tuned by reusing their parameters as a starting point and adding a task-specific layer trained from scratch. Fine-tuning the full model is also common and often yields better results, but is more computationally expensive.\\nFine-tuning is typically accomplished via supervised learning, but there are also techniques to fine-tune a model using weak supervision. Fine-tuning can be combined with a reinforcement learning from human feedback-based objective to produce language models such as ChatGPT (a fine-tuned version of GPT-3) and Sparrow.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Fine-tuning_(deep_learning)'}, page_content='In deep learning, fine-tuning is an approach to transfer learning in which the parameters of a pre-trained neural network model are trained on new data. Fine-tuning can be done on the entire neural network, or on only a subset of its layers, in which case the layers that are not being fine-tuned are \"frozen\" (i.e., not changed during backpropagation). A model may also be augmented with \"adapters\" that consist of far fewer parameters than the original model, and fine-tuned in a parameter-efficient way by tuning the weights of the adapters and leaving the rest of the model\\'s weights frozen.\\nFor some architectures, such as convolutional neural networks, it is common to keep the earlier layers (those closest to the input layer) frozen, as they capture lower-level features, while later layers often discern high-level features that can be more related to the task that the model is trained on.\\nModels that are pre-trained on large, general corpora are usually fine-tuned by reusing their parameters as a starting point and adding a task-specific layer trained from scratch. Fine-tuning the full model is also common and often yields better results, but is more computationally expensive.'),\n",
       " Document(metadata={'title': 'Fine-tuning (deep learning)', 'summary': 'In deep learning, fine-tuning is an approach to transfer learning in which the parameters of a pre-trained neural network model are trained on new data. Fine-tuning can be done on the entire neural network, or on only a subset of its layers, in which case the layers that are not being fine-tuned are \"frozen\" (i.e., not changed during backpropagation). A model may also be augmented with \"adapters\" that consist of far fewer parameters than the original model, and fine-tuned in a parameter-efficient way by tuning the weights of the adapters and leaving the rest of the model\\'s weights frozen.\\nFor some architectures, such as convolutional neural networks, it is common to keep the earlier layers (those closest to the input layer) frozen, as they capture lower-level features, while later layers often discern high-level features that can be more related to the task that the model is trained on.\\nModels that are pre-trained on large, general corpora are usually fine-tuned by reusing their parameters as a starting point and adding a task-specific layer trained from scratch. Fine-tuning the full model is also common and often yields better results, but is more computationally expensive.\\nFine-tuning is typically accomplished via supervised learning, but there are also techniques to fine-tune a model using weak supervision. Fine-tuning can be combined with a reinforcement learning from human feedback-based objective to produce language models such as ChatGPT (a fine-tuned version of GPT-3) and Sparrow.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Fine-tuning_(deep_learning)'}, page_content='Fine-tuning is typically accomplished via supervised learning, but there are also techniques to fine-tune a model using weak supervision. Fine-tuning can be combined with a reinforcement learning from human feedback-based objective to produce language models such as ChatGPT (a fine-tuned version of GPT-3) and Sparrow.'),\n",
       " Document(metadata={'title': 'Fine-tuning (deep learning)', 'summary': 'In deep learning, fine-tuning is an approach to transfer learning in which the parameters of a pre-trained neural network model are trained on new data. Fine-tuning can be done on the entire neural network, or on only a subset of its layers, in which case the layers that are not being fine-tuned are \"frozen\" (i.e., not changed during backpropagation). A model may also be augmented with \"adapters\" that consist of far fewer parameters than the original model, and fine-tuned in a parameter-efficient way by tuning the weights of the adapters and leaving the rest of the model\\'s weights frozen.\\nFor some architectures, such as convolutional neural networks, it is common to keep the earlier layers (those closest to the input layer) frozen, as they capture lower-level features, while later layers often discern high-level features that can be more related to the task that the model is trained on.\\nModels that are pre-trained on large, general corpora are usually fine-tuned by reusing their parameters as a starting point and adding a task-specific layer trained from scratch. Fine-tuning the full model is also common and often yields better results, but is more computationally expensive.\\nFine-tuning is typically accomplished via supervised learning, but there are also techniques to fine-tune a model using weak supervision. Fine-tuning can be combined with a reinforcement learning from human feedback-based objective to produce language models such as ChatGPT (a fine-tuned version of GPT-3) and Sparrow.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Fine-tuning_(deep_learning)'}, page_content=\"== Robustness ==\\nFine-tuning can degrade a model's robustness to distribution shifts. One mitigation is to linearly interpolate a fine-tuned model's weights with the weights of the original model, which can greatly increase out-of-distribution performance while largely retaining the in-distribution performance of the fine-tuned model.\\n\\n\\n== Variants ==\\n\\n\\n=== Low-rank adaptation ===\\nLow-rank adaptation (LoRA) is an adapter-based technique for efficiently fine-tuning models. The basic idea is to design a low-rank matrix that is then added to the original matrix. An adapter, in this context, is a collection of low-rank matrices which, when added to a base model, produces a fine-tuned model. It allows for performance that approaches full-model fine-tuning with less space requirement. A language model with billions of parameters may be LoRA fine-tuned with only several millions of parameters.\\nLoRA-based fine-tuning has become popular in the Stable Diffusion community. Support for LoRA was integrated into the Diffusers library from Hugging Face. Support for LoRA and similar techniques is also available for a wide range of other models through Hugging Face's Parameter-Efficient Fine-Tuning (PEFT) package.\\n\\n\\n=== Representation fine-tuning ===\"),\n",
       " Document(metadata={'title': 'Fine-tuning (deep learning)', 'summary': 'In deep learning, fine-tuning is an approach to transfer learning in which the parameters of a pre-trained neural network model are trained on new data. Fine-tuning can be done on the entire neural network, or on only a subset of its layers, in which case the layers that are not being fine-tuned are \"frozen\" (i.e., not changed during backpropagation). A model may also be augmented with \"adapters\" that consist of far fewer parameters than the original model, and fine-tuned in a parameter-efficient way by tuning the weights of the adapters and leaving the rest of the model\\'s weights frozen.\\nFor some architectures, such as convolutional neural networks, it is common to keep the earlier layers (those closest to the input layer) frozen, as they capture lower-level features, while later layers often discern high-level features that can be more related to the task that the model is trained on.\\nModels that are pre-trained on large, general corpora are usually fine-tuned by reusing their parameters as a starting point and adding a task-specific layer trained from scratch. Fine-tuning the full model is also common and often yields better results, but is more computationally expensive.\\nFine-tuning is typically accomplished via supervised learning, but there are also techniques to fine-tune a model using weak supervision. Fine-tuning can be combined with a reinforcement learning from human feedback-based objective to produce language models such as ChatGPT (a fine-tuned version of GPT-3) and Sparrow.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Fine-tuning_(deep_learning)'}, page_content='=== Representation fine-tuning ===\\n\\nRepresentation fine-tuning (ReFT) is a novel technique developed by researchers at Stanford University aimed at fine-tuning large language models (LLMs) by modifying less than 1% of their representations. Unlike traditional parameter-efficient fine-tuning (PEFT) methods, which mainly focus on updating weights, ReFT targets specific parts of the model relevant to the task being fine-tuned. This approach is based on the understanding that deep learning models encode rich semantic information in their representations, suggesting that modifying representations might be a more effective strategy than updating weights.\\nReFT methods operate on a frozen base model and learn task-specific interventions on hidden representations and train interventions that manipulate a small fraction of model representations to steer model behaviors towards solving downstream tasks at inference time. One specific method within the ReFT family is Low-rank Linear Subspace ReFT (LoReFT), which intervenes on hidden representations in the linear subspace spanned by a low-rank projection matrix. LoReFT can be seen as the representation-based equivalent of Low-rank Adaptation (LoRA).\\n\\n\\n== Applications ==\\n\\n\\n=== Natural language processing ==='),\n",
       " Document(metadata={'title': 'MMLU', 'summary': 'In artificial intelligence, Measuring Massive Multitask Language Understanding (MMLU) is a benchmark for evaluating the capabilities of large language models.', 'source': 'https://en.wikipedia.org/wiki/MMLU'}, page_content=\"In artificial intelligence, Measuring Massive Multitask Language Understanding (MMLU) is a benchmark for evaluating the capabilities of large language models.\\n\\n\\n== Benchmark ==\\nIt consists of about 16,000 multiple-choice questions spanning 57 academic subjects including mathematics, philosophy, law, and medicine. It is one of the most commonly used benchmarks for comparing the capabilities of large language models, with over 100 million downloads as of July 2024.\\nThe MMLU was released by Dan Hendrycks and a team of researchers in 2020 and was designed to be more challenging than then-existing benchmarks such as General Language Understanding Evaluation (GLUE) on which new language models were achieving better-than-human accuracy. At the time of the MMLU's release, most existing language models performed around the level of random chance (25%), with the best performing GPT-3 model achieving 43.9% accuracy. The developers of the MMLU estimate that human domain-experts achieve around 89.8% accuracy. As of 2024, some of the most powerful language models, such as o1, Gemini and Claude 3, were reported to achieve scores around 90%.\\nAn expert review of 3,000 randomly sampled questions found that over 9% of the questions are wrong (either the question is not well-defined, or that the given answer is wrong), which suggests that 90% is essentially the maximal achievable score.\"),\n",
       " Document(metadata={'title': 'MMLU', 'summary': 'In artificial intelligence, Measuring Massive Multitask Language Understanding (MMLU) is a benchmark for evaluating the capabilities of large language models.', 'source': 'https://en.wikipedia.org/wiki/MMLU'}, page_content='== Examples ==\\nThe following examples are taken from the \"Abstract Algebra\" and \"International Law\" tasks, respectively. The correct answers are marked in boldface:'),\n",
       " Document(metadata={'title': 'MMLU', 'summary': 'In artificial intelligence, Measuring Massive Multitask Language Understanding (MMLU) is a benchmark for evaluating the capabilities of large language models.', 'source': 'https://en.wikipedia.org/wiki/MMLU'}, page_content='Find all \\n  \\n    \\n      \\n        c\\n      \\n    \\n    {\\\\displaystyle c}\\n  \\n in \\n  \\n    \\n      \\n        \\n          \\n            Z\\n          \\n          \\n            3\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle \\\\mathbb {Z} _{3}}\\n  \\n such that \\n  \\n    \\n      \\n        \\n          \\n            Z\\n          \\n          \\n            3'),\n",
       " Document(metadata={'title': 'MMLU', 'summary': 'In artificial intelligence, Measuring Massive Multitask Language Understanding (MMLU) is a benchmark for evaluating the capabilities of large language models.', 'source': 'https://en.wikipedia.org/wiki/MMLU'}, page_content='3\\n          \\n        \\n        [\\n        x\\n        ]\\n        \\n          /\\n        \\n        (\\n        \\n          x\\n          \\n            2\\n          \\n        \\n        +\\n        c\\n        )\\n      \\n    \\n    {\\\\displaystyle \\\\mathbb {Z} _{3}[x]/(x^{2}+c)}\\n  \\n is a field.\\n(A) 0 (B) 1 (C) 2 (D) 3'),\n",
       " Document(metadata={'title': 'MMLU', 'summary': 'In artificial intelligence, Measuring Massive Multitask Language Understanding (MMLU) is a benchmark for evaluating the capabilities of large language models.', 'source': 'https://en.wikipedia.org/wiki/MMLU'}, page_content='Would a reservation to the definition of torture in the ICCPR be acceptable in contemporary practice?\\n(A) This is an acceptable reservation if the reserving country’s legislation employs a different definition\\n(B) This is an unacceptable reservation because it contravenes the object and purpose of the ICCPR\\n(C) This is an unacceptable reservation because the definition of torture in the ICCPR is consistent with customary international law\\n(D) This is an acceptable reservation because under general international law States have the right to enter reservations to treaties\\n\\n\\n== Leaderboard ==\\n\\n\\n== References =='),\n",
       " Document(metadata={'title': 'Open-source artificial intelligence', 'summary': 'Open-source artificial intelligence is an AI system that is freely available to use, study, modify, and share. These attributes extend to each of the system’s components, including datasets, code, and model parameters, promoting a collaborative and transparent approach to AI development.\\nFree and Open-Source Software (FOSS) licenses, such as the Apache License, MIT License, and GNU General Public License, outline the terms under which open-source artificial intelligence can be accessed, modified, and redistributed.\\nThe open-source model provides widespread access to new AI technologies, allowing individuals and organizations of all sizes to participate in AI research and development. This approach supports collaboration and allows for shared advancements within the field of artificial intelligence.\\nIn contrast, closed-source artificial intelligence is proprietary, restricting access to the source code and internal components. Only the owning company or organization can modify or distribute a closed-source artificial intelligence system, prioritizing control and protection of intellectual property over external contributions and transparency.\\nCompanies often develop closed products in an attempt to keep a competitive advantage in the marketplace. However, some experts suggest that open-source AI tools may have a development advantage over closed-source products and have the potential to overtake them in the marketplace.\\nPopular open-source artificial intelligence project categories include large language models, machine translation tools, and chatbots.\\nFor software developers to produce open-source artificial intelligence resources, they must trust the various other open-source software components they use in its development.\\nOpen-source artificial intelligence has been speculated to have potentially increased risk compared to closed-source artificial intelligence as bad actors may remove safety protocols of public models as they wish.', 'source': 'https://en.wikipedia.org/wiki/Open-source_artificial_intelligence'}, page_content='Open-source artificial intelligence is an AI system that is freely available to use, study, modify, and share. These attributes extend to each of the system’s components, including datasets, code, and model parameters, promoting a collaborative and transparent approach to AI development.\\nFree and Open-Source Software (FOSS) licenses, such as the Apache License, MIT License, and GNU General Public License, outline the terms under which open-source artificial intelligence can be accessed, modified, and redistributed.\\nThe open-source model provides widespread access to new AI technologies, allowing individuals and organizations of all sizes to participate in AI research and development. This approach supports collaboration and allows for shared advancements within the field of artificial intelligence.\\nIn contrast, closed-source artificial intelligence is proprietary, restricting access to the source code and internal components. Only the owning company or organization can modify or distribute a closed-source artificial intelligence system, prioritizing control and protection of intellectual property over external contributions and transparency.\\nCompanies often develop closed products in an attempt to keep a competitive advantage in the marketplace. However, some experts suggest that open-source AI tools may have a development advantage over closed-source products and have the potential to overtake them in the marketplace.\\nPopular open-source artificial intelligence project categories include large language models, machine translation tools, and chatbots.'),\n",
       " Document(metadata={'title': 'Open-source artificial intelligence', 'summary': 'Open-source artificial intelligence is an AI system that is freely available to use, study, modify, and share. These attributes extend to each of the system’s components, including datasets, code, and model parameters, promoting a collaborative and transparent approach to AI development.\\nFree and Open-Source Software (FOSS) licenses, such as the Apache License, MIT License, and GNU General Public License, outline the terms under which open-source artificial intelligence can be accessed, modified, and redistributed.\\nThe open-source model provides widespread access to new AI technologies, allowing individuals and organizations of all sizes to participate in AI research and development. This approach supports collaboration and allows for shared advancements within the field of artificial intelligence.\\nIn contrast, closed-source artificial intelligence is proprietary, restricting access to the source code and internal components. Only the owning company or organization can modify or distribute a closed-source artificial intelligence system, prioritizing control and protection of intellectual property over external contributions and transparency.\\nCompanies often develop closed products in an attempt to keep a competitive advantage in the marketplace. However, some experts suggest that open-source AI tools may have a development advantage over closed-source products and have the potential to overtake them in the marketplace.\\nPopular open-source artificial intelligence project categories include large language models, machine translation tools, and chatbots.\\nFor software developers to produce open-source artificial intelligence resources, they must trust the various other open-source software components they use in its development.\\nOpen-source artificial intelligence has been speculated to have potentially increased risk compared to closed-source artificial intelligence as bad actors may remove safety protocols of public models as they wish.', 'source': 'https://en.wikipedia.org/wiki/Open-source_artificial_intelligence'}, page_content='Popular open-source artificial intelligence project categories include large language models, machine translation tools, and chatbots.\\nFor software developers to produce open-source artificial intelligence resources, they must trust the various other open-source software components they use in its development.\\nOpen-source artificial intelligence has been speculated to have potentially increased risk compared to closed-source artificial intelligence as bad actors may remove safety protocols of public models as they wish.'),\n",
       " Document(metadata={'title': 'Open-source artificial intelligence', 'summary': 'Open-source artificial intelligence is an AI system that is freely available to use, study, modify, and share. These attributes extend to each of the system’s components, including datasets, code, and model parameters, promoting a collaborative and transparent approach to AI development.\\nFree and Open-Source Software (FOSS) licenses, such as the Apache License, MIT License, and GNU General Public License, outline the terms under which open-source artificial intelligence can be accessed, modified, and redistributed.\\nThe open-source model provides widespread access to new AI technologies, allowing individuals and organizations of all sizes to participate in AI research and development. This approach supports collaboration and allows for shared advancements within the field of artificial intelligence.\\nIn contrast, closed-source artificial intelligence is proprietary, restricting access to the source code and internal components. Only the owning company or organization can modify or distribute a closed-source artificial intelligence system, prioritizing control and protection of intellectual property over external contributions and transparency.\\nCompanies often develop closed products in an attempt to keep a competitive advantage in the marketplace. However, some experts suggest that open-source AI tools may have a development advantage over closed-source products and have the potential to overtake them in the marketplace.\\nPopular open-source artificial intelligence project categories include large language models, machine translation tools, and chatbots.\\nFor software developers to produce open-source artificial intelligence resources, they must trust the various other open-source software components they use in its development.\\nOpen-source artificial intelligence has been speculated to have potentially increased risk compared to closed-source artificial intelligence as bad actors may remove safety protocols of public models as they wish.', 'source': 'https://en.wikipedia.org/wiki/Open-source_artificial_intelligence'}, page_content='== History ==\\nThe history of open-source artificial intelligence (AI) is intertwined with both the development of AI technologies and the growth of the open-source software movement. Open-source AI has evolved significantly over the past few decades, with contributions from various academic institutions, research labs, tech companies, and independent developers. This section explores the major milestones in the development of open-source AI, from its early days to its current state.\\n\\n\\n=== Early development of AI and open-source software ===\\nThe concept of AI dates back to the mid-20th century, when computer scientists like Alan Turing and John McCarthy laid the groundwork for modern AI theories and algorithms. Early AI research focused on developing symbolic reasoning systems and rule-based expert systems. During this period, the idea of open-source software was beginning to take shape, with pioneers like Richard Stallman advocating for free software as a means to promote collaboration and innovation in programming.\\nThe Free Software Foundation, founded in 1985 by Stallman, was one of the first major organizations to promote the idea of software that could be freely used, modified, and distributed. The ideas from this movement eventually influenced the development of open-source AI, as more developers began to see the potential benefits of open collaboration in software creation, including AI models and algorithms.'),\n",
       " Document(metadata={'title': 'Open-source artificial intelligence', 'summary': 'Open-source artificial intelligence is an AI system that is freely available to use, study, modify, and share. These attributes extend to each of the system’s components, including datasets, code, and model parameters, promoting a collaborative and transparent approach to AI development.\\nFree and Open-Source Software (FOSS) licenses, such as the Apache License, MIT License, and GNU General Public License, outline the terms under which open-source artificial intelligence can be accessed, modified, and redistributed.\\nThe open-source model provides widespread access to new AI technologies, allowing individuals and organizations of all sizes to participate in AI research and development. This approach supports collaboration and allows for shared advancements within the field of artificial intelligence.\\nIn contrast, closed-source artificial intelligence is proprietary, restricting access to the source code and internal components. Only the owning company or organization can modify or distribute a closed-source artificial intelligence system, prioritizing control and protection of intellectual property over external contributions and transparency.\\nCompanies often develop closed products in an attempt to keep a competitive advantage in the marketplace. However, some experts suggest that open-source AI tools may have a development advantage over closed-source products and have the potential to overtake them in the marketplace.\\nPopular open-source artificial intelligence project categories include large language models, machine translation tools, and chatbots.\\nFor software developers to produce open-source artificial intelligence resources, they must trust the various other open-source software components they use in its development.\\nOpen-source artificial intelligence has been speculated to have potentially increased risk compared to closed-source artificial intelligence as bad actors may remove safety protocols of public models as they wish.', 'source': 'https://en.wikipedia.org/wiki/Open-source_artificial_intelligence'}, page_content=\"=== Emergence of open-source AI (1990s-2000s) ===\\nIn the 1990s, open-source software began to gain more traction as the internet facilitated collaboration across geographical boundaries. The rise of machine learning and statistical methods also led to the development of more practical AI tools. However, it wasn't until the early 2000s that open-source AI began to take off, with the release of foundational libraries and frameworks that were available for anyone to use and contribute to.\\nOne of the early open-source AI frameworks was Scikit-learn, released in 2007. Scikit-learn becam\"),\n",
       " Document(metadata={'title': 'BLOOM (language model)', 'summary': \"BigScience Large Open-science Open-access Multilingual Language Model (BLOOM) is a 176-billion-parameter transformer-based autoregressive large language model (LLM). The model, as well as the code base and the data used to train it, are distributed under free licences. BLOOM was trained on approximately 366 billion (1.6TB) tokens from March to July 2022.\\nBLOOM is the main outcome of the BigScience collaborative initiative, a one-year-long research workshop that took place between May 2021 and May 2022. BigScience was led by HuggingFace and involved several hundreds of researchers and engineers from France and abroad representing both the academia and the private sector. BigScience was supported by a large-scale public compute grant on the French public supercomputer Jean Zay, managed by GENCI and IDRIS (CNRS), on which it was trained.\\nBLOOM's training corpus, named ROOTS, combines data extracted from the then-latest version of the web-based OSCAR corpus (38% of ROOTS) and newly collected data extracted from a manually selected and documented list of language data sources. It encompasses 46 natural languages (in amounts ranging from 30% of the whole dataset for English to 0.00002% for Chi Tumbuka) and 13 programming languages.\", 'source': 'https://en.wikipedia.org/wiki/BLOOM_(language_model)'}, page_content=\"BigScience Large Open-science Open-access Multilingual Language Model (BLOOM) is a 176-billion-parameter transformer-based autoregressive large language model (LLM). The model, as well as the code base and the data used to train it, are distributed under free licences. BLOOM was trained on approximately 366 billion (1.6TB) tokens from March to July 2022.\\nBLOOM is the main outcome of the BigScience collaborative initiative, a one-year-long research workshop that took place between May 2021 and May 2022. BigScience was led by HuggingFace and involved several hundreds of researchers and engineers from France and abroad representing both the academia and the private sector. BigScience was supported by a large-scale public compute grant on the French public supercomputer Jean Zay, managed by GENCI and IDRIS (CNRS), on which it was trained.\\nBLOOM's training corpus, named ROOTS, combines data extracted from the then-latest version of the web-based OSCAR corpus (38% of ROOTS) and newly collected data extracted from a manually selected and documented list of language data sources. It encompasses 46 natural languages (in amounts ranging from 30% of the whole dataset for English to 0.00002% for Chi Tumbuka) and 13 programming languages.\\n\\n\\n== References ==\"),\n",
       " Document(metadata={'title': 'Multimodal learning', 'summary': 'Multimodal learning is a type of deep learning that integrates and processes multiple types of data, referred to as  modalities, such as text, audio, images, or video. This integration allows for a more holistic understanding of complex data, improving model performance in tasks like visual question answering, cross-modal retrieval, text-to-image generation, aesthetic ranking, and image captioning.\\nLarge multimodal models, such as Google Gemini and GPT-4o, have become increasingly popular since 2023, enabling increased versatility and a broader understanding of real-world phenomena.', 'source': 'https://en.wikipedia.org/wiki/Multimodal_learning'}, page_content='Multimodal learning is a type of deep learning that integrates and processes multiple types of data, referred to as  modalities, such as text, audio, images, or video. This integration allows for a more holistic understanding of complex data, improving model performance in tasks like visual question answering, cross-modal retrieval, text-to-image generation, aesthetic ranking, and image captioning.\\nLarge multimodal models, such as Google Gemini and GPT-4o, have become increasingly popular since 2023, enabling increased versatility and a broader understanding of real-world phenomena.\\n\\n\\n== Motivation ==\\nData usually comes with different modalities which carry different information. For example, it is very common to caption an image to convey the information not presented in the image itself. Similarly, sometimes it is more straightforward to use an image to describe information which may not be obvious from text. As a result, if different words appear in similar images, then these words likely describe the same thing. Conversely, if a word is used to describe seemingly dissimilar images, then these images may represent the same object. Thus, in cases dealing with multi-modal data, it is important to use a model which is able to jointly represent the information such that the model can capture the combined information from different modalities.\\n\\n\\n== Multimodal transformers ==\\n\\n\\n=== Multimodal large language models ==='),\n",
       " Document(metadata={'title': 'Multimodal learning', 'summary': 'Multimodal learning is a type of deep learning that integrates and processes multiple types of data, referred to as  modalities, such as text, audio, images, or video. This integration allows for a more holistic understanding of complex data, improving model performance in tasks like visual question answering, cross-modal retrieval, text-to-image generation, aesthetic ranking, and image captioning.\\nLarge multimodal models, such as Google Gemini and GPT-4o, have become increasingly popular since 2023, enabling increased versatility and a broader understanding of real-world phenomena.', 'source': 'https://en.wikipedia.org/wiki/Multimodal_learning'}, page_content='== Multimodal transformers ==\\n\\n\\n=== Multimodal large language models ===\\n\\n\\n== Multimodal deep Boltzmann machines ==\\nA Boltzmann machine is a type of stochastic neural network invented by Geoffrey Hinton and Terry Sejnowski in 1985. Boltzmann machines can be seen as the stochastic, generative counterpart of Hopfield nets. They are named after the Boltzmann distribution in statistical mechanics. The units in Boltzmann machines are divided into two groups: visible units and hidden units. Each unit is like a neuron with a binary output that represents whether it is activated or not. General Boltzmann machines allow connection between any units. However, learning is impractical using general Boltzmann Machines because the computational time is exponential to the size of the machine. A more efficient architecture is called restricted Boltzmann machine where connection is only allowed between hidden unit and visible unit, which is described in the next section.\\nMultimodal deep Boltzmann machines can process and learn from different types of information, such as images and text, simultaneously. This can notably be done by having a separate deep Boltzmann machine for each modality, for example one for images and one for text, joined at an additional top hidden layer.\\n\\n\\n== Applications ==\\nMultimodal machine learning has numerous applications across various domains:'),\n",
       " Document(metadata={'title': 'Multimodal learning', 'summary': 'Multimodal learning is a type of deep learning that integrates and processes multiple types of data, referred to as  modalities, such as text, audio, images, or video. This integration allows for a more holistic understanding of complex data, improving model performance in tasks like visual question answering, cross-modal retrieval, text-to-image generation, aesthetic ranking, and image captioning.\\nLarge multimodal models, such as Google Gemini and GPT-4o, have become increasingly popular since 2023, enabling increased versatility and a broader understanding of real-world phenomena.', 'source': 'https://en.wikipedia.org/wiki/Multimodal_learning'}, page_content='== Applications ==\\nMultimodal machine learning has numerous applications across various domains:\\n\\n\\n=== Cross-Modal Retrieval ===\\nCross-modal retrieval allows users to search for data across different modalities (e.g., retrieving images based on text descriptions), improving multimedia search engines and content recommendation systems. Models like CLIP facilitate efficient, accurate retrieval by embedding data in a shared space, demonstrating strong performance even in zero-shot settings.\\n\\n\\n=== Classification and Missing Data Retrieval ===\\nMultimodal Deep Boltzmann Machines outperform traditional models like support vector machines and latent Dirichlet allocation in classification tasks and can predict missing data in multimodal datasets, such as images and text.\\n\\n\\n=== Healthcare Diagnostics ===\\nMultimodal models integrate medical imaging, genomic data, and patient records to improve diagnostic accuracy and early disease detection, especially in cancer screening.\\n\\n\\n=== Content Generation ===\\nModels like DALL·E generate images from textual descriptions, benefiting creative industries, while cross-modal retrieval enables dynamic multimedia searches.\\n\\n\\n=== Robotics and HCI ===\\nMultimodal learning improves interaction in robotics and AI by integrating sensory inputs like speech, vision, and touch, aiding autonomous systems and human-com')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jGOJOS2gajM"
   },
   "source": [
    "### Create the Vector Store\n",
    "\n",
    "Now, we'll embed the documents using OpenAIEmbeddings and store them in Chroma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xgckI08xl4kn"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R4G3kIku6TXf"
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LoCFshqvKtO2"
   },
   "source": [
    "## **Step 3:** Multi-Query Generation\n",
    "In this step, we'll generate multiple alternative versions of the user's query. This allows the retrieval system to explore different angles of the same query, which can improve the quality of the retrieved documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08A8Ey7Cmrjd"
   },
   "source": [
    "### Define LLM Model Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hnl2WmmfmoC6"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ecGH2CTh_yA"
   },
   "source": [
    "### Define the Multi-Query Prompt\n",
    "\n",
    "We will use a prompt to instruct the large language model to generate five alternative questions based on the user's input. The goal is to help the system overcome some limitations of distance-based similarity search by exploring different query perspectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xV_jJnE_6Vtq"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Define the multi-query generation prompt\n",
    "template = '''You are an AI language model assistant. Your task is to generate five\n",
    "different versions of the given user question to retrieve relevant documents from a vector\n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search.\n",
    "Provide these alternative questions as well as the original question separated by newlines. Original question: {question}'''\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vOpeCQQm8_B"
   },
   "source": [
    "### Define the Query Generation Chain\n",
    "\n",
    "Now let's define a langchain query generation chain to use the prompt and generate an llm response with 5 alternative queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lK_Raz85nbno"
   },
   "outputs": [],
   "source": [
    "# Define the query generation chain\n",
    "generate_queries = (\n",
    "    prompt_perspectives\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Q9promEiKTX"
   },
   "source": [
    "### Generate Alternative Queries\n",
    "Now we will generate alternative queries based on a sample question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zKuGUa-TK4g3",
    "outputId": "7d99e430-ca29-456c-ffac-a9f1fbd84c3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Multi-Queries:\n",
      "How can one evaluate the effectiveness of a large language model?\n",
      "What are the methods for assessing the performance of a large language model?\n",
      "In what ways can the performance of a large language model be gauged?\n",
      "What criteria are used to measure the performance of a large language model?\n",
      "How do you determine the efficiency of a large language model?\n",
      "How to measure the performance of a large language model?\n"
     ]
    }
   ],
   "source": [
    "# Generate and store alternative queries\n",
    "question = \"How to measure the performance of a large language model?\"\n",
    "alternative_queries = generate_queries.invoke({\"question\": question})\n",
    "\n",
    "# Display the generated queries\n",
    "print(\"Generated Multi-Queries:\")\n",
    "for i, q in enumerate(alternative_queries, start=1):\n",
    "    if q:\n",
    "        print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VT8G_LGOLVFo"
   },
   "source": [
    "## **Step 4:** Document Retrieval Using Multi-Query\n",
    "\n",
    "With our alternative queries in hand, we can now use them to retrieve relevant documents from the vector store. By querying the store with multiple variations of the same query, we increase the likelihood of retrieving more relevant documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JV-WjMjiiR1H"
   },
   "source": [
    "### Retrieve Documents for Each Alternative Query\n",
    "We will now implement a retriever chain to retrieve documents based on the multi-queries and merge them to eliminate duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H8_rReGIQQ74"
   },
   "outputs": [],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\" Unique union of retrieved docs \"\"\"\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "# Multi Query Retrieval Chain\n",
    "multi_query_retrieval_chain = generate_queries | retriever.map() | get_unique_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Huu_GxegQgsK",
    "outputId": "4748f3e5-7700-47b6-9b7a-c96bb656fe8d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-1a30b6dc7785>:7: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  return [loads(doc) for doc in unique_docs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = multi_query_retrieval_chain.invoke({\"question\": question})\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Q5paQLNLzlf"
   },
   "source": [
    "## **Step 5:** Generate the Final Answer\n",
    "Now that we have the relevant documents, we can generate the final answer using the RAG framework. The retrieved documents will be passed as context to the LLM, which will then generate a response based on the provided information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1nhyc3CibXL"
   },
   "source": [
    "### Define the Answer Generation Prompt\n",
    "Create a prompt that instructs the model to answer the user's question based on the provided context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ANyqJ8j06Zz-"
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "template = \"\"\"Answer the following question based on the context. NEVER include anything from outside the already provided context.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "multi_query_rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | multi_query_retrieval_chain,\n",
    "     \"question\": itemgetter(\"question\")}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCh5JaYWL7K6"
   },
   "source": [
    "## **Step 6:** Comparison of RAG with and without Multi-query\n",
    "To understand the effectiveness of multi-query retrieval, let's compare it with a baseline RAG system that uses a single query for document retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmQVC7bvilgZ"
   },
   "source": [
    "### Baseline RAG: Single Query Retrieval\n",
    "For the baseline, we'll use a single query to retrieve documents and generate an answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CbiBrsUuYTuO"
   },
   "outputs": [],
   "source": [
    "baseline_retrieval_chain = retriever\n",
    "baseline_rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | baseline_retrieval_chain,\n",
    "     \"question\": itemgetter(\"question\")}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYgT_v45ioxk"
   },
   "source": [
    "### Compare the Responses\n",
    "Now, let's use the multi-query rag chain and baseline rag chain side by side and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MMrs8E6AD6yC",
    "outputId": "df1b915b-9ab6-477b-8903-9ef9201a54c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RAG Result:\n",
      " The performance of a large language model can be measured by evaluating its capabilities on various natural language processing benchmarks and tasks.\n",
      "\n",
      "\n",
      "Multi Query RAG Result:\n",
      " The performance of a large language model can be measured using benchmarks such as Measuring Massive Multitask Language Understanding (MMLU), which consists of multiple-choice questions spanning various academic subjects. These benchmarks help evaluate the capabilities of large language models by testing their accuracy in answering questions across different domains.\n"
     ]
    }
   ],
   "source": [
    "question_input = {\"question\": \"How to measure the performance of a large language model?\"}\n",
    "\n",
    "baseline_result = baseline_rag_chain.invoke(question_input)\n",
    "print(\"Baseline RAG Result:\\n\", baseline_result)\n",
    "\n",
    "enhanced_result = multi_query_rag_chain.invoke(question_input)\n",
    "print(\"\\n\\nMulti Query RAG Result:\\n\", enhanced_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uo-SOMdWpYv_"
   },
   "source": [
    "By comparing the responses from both the baseline and multi-query RAG, it is clear that the baseline failed to retrieve any relevant documents or generate a meaningful response. In contrast, the multi-query approach successfully retrieved pertinent documents and generated a coherent response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XoXTxEVitWY"
   },
   "source": [
    "## Conclusion\n",
    "In this guide, you learned how to implement multi-query retrieval in a RAG system. By generating multiple versions of a user’s query and retrieving documents based on these variations, you can improve the accuracy of your system’s responses.\n",
    "\n",
    "### Key Steps:\n",
    "- Set up the environment and API keys.\n",
    "- Ingest and index documents into a vector store.\n",
    "- Generate alternative queries using a language model.\n",
    "- Retrieve documents based on multiple queries.\n",
    "- Generate final answers based on the retrieved context.\n",
    "- Compare the performance of RAG with and without multi-query retrieval.\n",
    "\n",
    "\n",
    "By following this process, you can significantly improve the performance and user experience of your RAG system!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
